{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6325cc0a-faad-415f-b768-e8ff3ae59d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: amazon_reviews.txt\n",
      "  input_format: \n",
      "  model_prefix: amazon_reviews\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 16000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: amazon_reviews.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 112032 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=15424622\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=95\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 112032 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=8665450\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 83355 seed sentencepieces\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 112032\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 90740\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 90740 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=35198 obj=10.0011 num_tokens=205491 num_tokens/piece=5.83814\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=30303 obj=7.84363 num_tokens=207362 num_tokens/piece=6.84295\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=22723 obj=7.80598 num_tokens=215430 num_tokens/piece=9.4807\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=22710 obj=7.79839 num_tokens=215870 num_tokens/piece=9.5055\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=17599 obj=7.83138 num_tokens=227650 num_tokens/piece=12.9354\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=17598 obj=7.82446 num_tokens=227655 num_tokens/piece=12.9364\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: amazon_reviews.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: amazon_reviews.vocab\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "file = \"amazon_review.csv\"\n",
    "\n",
    "data = pd.read_csv(file).dropna(ignore_index=True)\n",
    "data['overall'] = data[\"overall\"] - 1\n",
    "\n",
    "vocab_size = 16000\n",
    "seq_len = 512\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='amazon_reviews.txt',\n",
    "    model_prefix='amazon_reviews',\n",
    "    vocab_size=vocab_size,\n",
    "    model_type='unigram',\n",
    "    character_coverage=1.0\n",
    ")\n",
    "\n",
    "tok = spm.SentencePieceProcessor(model_file='amazon_reviews.model')\n",
    "\n",
    "filter_ = 1\n",
    "\n",
    "ls  = [len(tok.encode(i, out_type=int)) for i in data[\"reviewText\"]]\n",
    "\n",
    "data[\"lengths\"] = ls\n",
    "\n",
    "data_trunc = data[data[\"lengths\"]<=80]\n",
    "\n",
    "v = data_trunc[\"overall\"].value_counts()\n",
    "\n",
    "balanced_data = (\n",
    "    data_trunc.groupby(\"overall\")\n",
    "      .sample(n=min(v), random_state=42)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "len(balanced_data)\n",
    "\n",
    "df_shuffled = balanced_data.sample(frac=filter_, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split the shuffled DataFrame\n",
    "train_size = 0.8\n",
    "train_df = df_shuffled.sample(frac=train_size, random_state=42).reset_index(drop=True)\n",
    "test_df = df_shuffled.drop(train_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "81bde877-51c4-416f-a49f-a446afd66bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train df:  15396\n",
      "len test df:  3849\n"
     ]
    }
   ],
   "source": [
    "print(\"len train df: \", len(train_df))\n",
    "print(\"len test df: \", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4fe9bc00-5382-476c-8d6a-37d37c8d6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one input output pair with special tokens for later concatenation with other pairs for one sequence under max sequence length\n",
    "def getEncodingOpen(df, i):\n",
    "    reviewtext = \"Review: \"+ df[\"reviewText\"].iloc[i]\n",
    "    rating = \"Rating: \" \n",
    "    #row = [16000] + tok.encode(reviewText, out_type=int) + [16001] + tok.encode([int(df[\"overall\"].iloc[i])], out_type = int)\n",
    "    row = [16000] + tok.encode(reviewtext, out_type = int) + [16002] + tok.encode(rating, out_type = int)\n",
    "    correct_output_rating = int(df[\"overall\"].iloc[i])\n",
    "    row = torch.LongTensor(row)\n",
    "    correct_output_rating = torch.LongTensor([correct_output_rating])\n",
    "    return row, correct_output_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ac402251-1edf-4d2f-bbec-c97bfdae231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one input output pair with special tokens for later concatenation with other pairs for one sequence under max sequence length\n",
    "def getEncoding(df, i):\n",
    "    reviewtext = \"Review: \"+ df[\"reviewText\"].iloc[i]\n",
    "    rating = \"Rating: \" + str(int(df[\"overall\"].iloc[i])+16003)\n",
    "    #row = [16000] + tok.encode(reviewText, out_type=int) + [16001] + tok.encode([int(df[\"overall\"].iloc[i])], out_type = int)\n",
    "    row = [16000] + tok.encode(reviewtext, out_type = int) + [16002] + tok.encode(rating, out_type = int) + [16001]\n",
    "    return row\n",
    "\n",
    "def getShiftSeq(df_t, max_seq=1024):\n",
    "    seqs_x = []\n",
    "    seqs_y = []\n",
    "    seqs = []\n",
    "    c = []\n",
    "    for i in range(len(df_t)):\n",
    "        row = getEncoding(train_df, i)\n",
    "        if len(c) + len(row) > max_seq +1:\n",
    "            seqs_x.append(c[:-1])\n",
    "            seqs_y.append(c[1:])\n",
    "            seqs.append(c)\n",
    "            c = []\n",
    "        c.extend(row)\n",
    "    return seqs_x, seqs_y, seqs\n",
    "\n",
    "train_seqs_x, train_seqs_y, train_seqs = getShiftSeq(train_df, max_seq=seq_len)\n",
    "test_seqs_x, test_seqs_y, test_seqs = getShiftSeq(test_df, max_seq=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "39283dd5-fa89-40ad-8261-587122857b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDatasetB(Dataset):\n",
    "    def __init__(self, seqs_x, seqs_y):\n",
    "        self.seqs_x = seqs_x\n",
    "        self.seqs_y = seqs_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.seqs_x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.seqs_x[idx]), torch.LongTensor(self.seqs_y[idx])\n",
    "\n",
    "# Padding collate function for variable length sequences\n",
    "def collate_fnB(batch):\n",
    "    seqs_x, seqs_y = zip(*batch)\n",
    "    lens = [len(s) for s in seqs_x]\n",
    "    max_len = max(lens)\n",
    "    \n",
    "    # Pad sequences\n",
    "    padded_x = torch.zeros(len(seqs_x), max_len, dtype=torch.long)\n",
    "    padded_y = torch.zeros(len(seqs_y), max_len, dtype=torch.long)\n",
    "    \n",
    "    for i, (x, y) in enumerate(zip(seqs_x, seqs_y)):\n",
    "        padded_x[i, :len(x)] = x\n",
    "        padded_y[i, :len(y)] = y\n",
    "    \n",
    "    return padded_x, padded_y, torch.LongTensor(lens)\n",
    "\n",
    "dataset = TokenDatasetB(train_seqs_x, train_seqs_y)\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fnB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5d463056-66fe-4da7-9128-e3e7f7bb7e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi\n",
      "0\n",
      "x\n",
      "tensor([[16000,  7421,   292,   139,  1183,     6,    36,   297,    61,    23,\n",
      "           994,     3, 12660,    26,   231,   158,   245,    30,    79,     6,\n",
      "             4,    41,     8,   381,  1164,     7,   137,    31,    16,     8,\n",
      "           381,     3,  1716,    35,   495,    67,  6214, 16002, 13254,   292,\n",
      "          4037, 12507, 16001, 16000,  7421,   292,    45,    19,    49,     3,\n",
      "          1051,    47,     7,    19,  1213,  1125,    37,  2363,  2290,  1741,\n",
      "             3, 16002, 13254,   292,  1736, 12473, 16001, 16000,  7421,   292,\n",
      "           949,    14,    10,    15,     5,   390,     6,    23,    24,   301,\n",
      "             9,   257,     9,  1165,     8,    74,   551,     3,    39,   715,\n",
      "           143,   277,  1776,   172,   807,   150,   152,   114,     8,   774,\n",
      "             3, 16002, 13254,   292,  1736,  2301,  1974, 16001, 16000,  7421,\n",
      "           292,   815,     8,  1738,     7,    14,    10,    15,  8966,  4124,\n",
      "            53,   117,     3,    39,   971,   521,  1348,   134,    23,     5,\n",
      "           168,    13,    66,  8042,     7,  9343,     3,   901,     8,    82,\n",
      "           148,     7,     4,    58,    41,    14,     9,    59,    32,     8,\n",
      "          4246,   310,     3, 16002, 13254,   292,  1736, 14419, 16001, 16000,\n",
      "          7421,   292,  1186,    15,  2850,    78, 16002, 13254,   292,  1736,\n",
      "         10110, 16001, 16000,  7421,   292,   606,   184,   173,   868,     7,\n",
      "           845,  4015,    26,    13,   176, 16002, 13254,   292,  1736, 10110,\n",
      "         16001, 16000,  7421,   292,     4,    27,     9,   284,    25,     4,\n",
      "            27,   127,   110,   415,  4941,    11,   101,     7,     9,    46,\n",
      "          3091,    24,    19,     5,   115, 14172,     4,    27,   164,   249,\n",
      "             4,   685,     7,     4,    27,   116,   965,     3, 16002, 13254,\n",
      "           292,  1736, 12473, 16001, 16000,  7421,   292,   976,    38,    61,\n",
      "            11,   551,    89,     3, 16002, 13254,   292,  1736, 12473, 16001,\n",
      "         16000,  7421,   292,   336,    38,    34,   139,    49,     4,    69,\n",
      "          1074,   341,   468,    30,   199,    56,    42,   400,    19,     3,\n",
      "         16002, 13254,   292,  4037, 12507, 16001, 16000,  7421,   292,    39,\n",
      "           218,   567,   158,   287,    34,     4,   219,     9,   248,    23,\n",
      "             4,    33,   186,   339,   518,     5,   390,   174,    34,     4,\n",
      "           219,    37,  2923,     9,   248,    31,  1680,     7,    40,   567,\n",
      "           158,    34,   109,    33,  1471,  7247,     7,     4,    69,    27,\n",
      "           345,    18, 10460,  1299,    69,    27,   127,  2423,    34,    39,\n",
      "          1078,   158,    13,    37,   121,   176,     7,    14,    13,     8,\n",
      "           176,    91,    34, 16002, 13254,   292,  1736, 10110, 16001, 16000,\n",
      "          7421,   292,    26,    87, 16002, 13254,   292,  4037, 12507, 16001,\n",
      "         16000,  7421,   292,   441,   241,    51,     9,  1524,    18,   856,\n",
      "           211,   230,   362,  9730,   252,     7,  4732, 16002, 13254,   292,\n",
      "          1736, 14419, 16001, 16000,  7421,   292,   181,    26,    82,    44,\n",
      "            38,    11,    60,  9511,     3, 16002, 13254,   292,  4037, 12507,\n",
      "         16001, 16000,  7421,   292,   147,    21, 16002, 13254,   292,  1736,\n",
      "         12473, 16001, 16000,  7421,   292,     4,    27,   200,    54,    17,\n",
      "            24,    50,    25,    19,   466,   348,  1017,     7,    22,    26,\n",
      "            87,     3,    31,    54,   492,    13,   184,    16,     5,    23,\n",
      "            29,     7,   868,     4,    10,    76,  1972,    14,    58,   115,\n",
      "            80,  2224,    35,     4,   294,    21,     3,   224,    97,    42,\n",
      "           304,    80,   466,   348,  1017,   350,   466,   348,  4748, 16002,\n",
      "         13254,   292,  1736, 14419, 16001, 16000,  7421,   292,   188,  3221,\n",
      "           186,   587,    53,    78,     3,   949,     4,    55,   111,    10,\n",
      "            29,   227,     5,   983,   684,   439,    26,     7,  3332,    26,\n",
      "           357, 16002, 13254,   292,  1736, 14419]])\n",
      "torch.Size([1, 506])\n",
      "y\n",
      "tensor([[ 7421,   292,   139,  1183,     6,    36,   297,    61,    23,   994,\n",
      "             3, 12660,    26,   231,   158,   245,    30,    79,     6,     4,\n",
      "            41,     8,   381,  1164,     7,   137,    31,    16,     8,   381,\n",
      "             3,  1716,    35,   495,    67,  6214, 16002, 13254,   292,  4037,\n",
      "         12507, 16001, 16000,  7421,   292,    45,    19,    49,     3,  1051,\n",
      "            47,     7,    19,  1213,  1125,    37,  2363,  2290,  1741,     3,\n",
      "         16002, 13254,   292,  1736, 12473, 16001, 16000,  7421,   292,   949,\n",
      "            14,    10,    15,     5,   390,     6,    23,    24,   301,     9,\n",
      "           257,     9,  1165,     8,    74,   551,     3,    39,   715,   143,\n",
      "           277,  1776,   172,   807,   150,   152,   114,     8,   774,     3,\n",
      "         16002, 13254,   292,  1736,  2301,  1974, 16001, 16000,  7421,   292,\n",
      "           815,     8,  1738,     7,    14,    10,    15,  8966,  4124,    53,\n",
      "           117,     3,    39,   971,   521,  1348,   134,    23,     5,   168,\n",
      "            13,    66,  8042,     7,  9343,     3,   901,     8,    82,   148,\n",
      "             7,     4,    58,    41,    14,     9,    59,    32,     8,  4246,\n",
      "           310,     3, 16002, 13254,   292,  1736, 14419, 16001, 16000,  7421,\n",
      "           292,  1186,    15,  2850,    78, 16002, 13254,   292,  1736, 10110,\n",
      "         16001, 16000,  7421,   292,   606,   184,   173,   868,     7,   845,\n",
      "          4015,    26,    13,   176, 16002, 13254,   292,  1736, 10110, 16001,\n",
      "         16000,  7421,   292,     4,    27,     9,   284,    25,     4,    27,\n",
      "           127,   110,   415,  4941,    11,   101,     7,     9,    46,  3091,\n",
      "            24,    19,     5,   115, 14172,     4,    27,   164,   249,     4,\n",
      "           685,     7,     4,    27,   116,   965,     3, 16002, 13254,   292,\n",
      "          1736, 12473, 16001, 16000,  7421,   292,   976,    38,    61,    11,\n",
      "           551,    89,     3, 16002, 13254,   292,  1736, 12473, 16001, 16000,\n",
      "          7421,   292,   336,    38,    34,   139,    49,     4,    69,  1074,\n",
      "           341,   468,    30,   199,    56,    42,   400,    19,     3, 16002,\n",
      "         13254,   292,  4037, 12507, 16001, 16000,  7421,   292,    39,   218,\n",
      "           567,   158,   287,    34,     4,   219,     9,   248,    23,     4,\n",
      "            33,   186,   339,   518,     5,   390,   174,    34,     4,   219,\n",
      "            37,  2923,     9,   248,    31,  1680,     7,    40,   567,   158,\n",
      "            34,   109,    33,  1471,  7247,     7,     4,    69,    27,   345,\n",
      "            18, 10460,  1299,    69,    27,   127,  2423,    34,    39,  1078,\n",
      "           158,    13,    37,   121,   176,     7,    14,    13,     8,   176,\n",
      "            91,    34, 16002, 13254,   292,  1736, 10110, 16001, 16000,  7421,\n",
      "           292,    26,    87, 16002, 13254,   292,  4037, 12507, 16001, 16000,\n",
      "          7421,   292,   441,   241,    51,     9,  1524,    18,   856,   211,\n",
      "           230,   362,  9730,   252,     7,  4732, 16002, 13254,   292,  1736,\n",
      "         14419, 16001, 16000,  7421,   292,   181,    26,    82,    44,    38,\n",
      "            11,    60,  9511,     3, 16002, 13254,   292,  4037, 12507, 16001,\n",
      "         16000,  7421,   292,   147,    21, 16002, 13254,   292,  1736, 12473,\n",
      "         16001, 16000,  7421,   292,     4,    27,   200,    54,    17,    24,\n",
      "            50,    25,    19,   466,   348,  1017,     7,    22,    26,    87,\n",
      "             3,    31,    54,   492,    13,   184,    16,     5,    23,    29,\n",
      "             7,   868,     4,    10,    76,  1972,    14,    58,   115,    80,\n",
      "          2224,    35,     4,   294,    21,     3,   224,    97,    42,   304,\n",
      "            80,   466,   348,  1017,   350,   466,   348,  4748, 16002, 13254,\n",
      "           292,  1736, 14419, 16001, 16000,  7421,   292,   188,  3221,   186,\n",
      "           587,    53,    78,     3,   949,     4,    55,   111,    10,    29,\n",
      "           227,     5,   983,   684,   439,    26,     7,  3332,    26,   357,\n",
      "         16002, 13254,   292,  1736, 14419, 16001]])\n",
      "torch.Size([1, 506])\n",
      "lengths\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([506])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch_idx, (x, y, lengths) in enumerate(train_loader):\n",
    "    print(\"bi\")\n",
    "    print(batch_idx)\n",
    "    print(\"x\")\n",
    "    print(x)\n",
    "    print(x.shape)\n",
    "    print(\"y\")\n",
    "    print(y)\n",
    "    print(y.shape)\n",
    "    print(\"lengths\")\n",
    "    print(lengths.shape)\n",
    "    break\n",
    "\n",
    "lengths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c553b33d-3abc-4f4e-96ba-c6e56fbf37bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "CUDA device count: 1\n",
      "Current CUDA device name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use the CPU.\")\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "70e18ed8-d2cc-4928-8ac3-3bdf65780839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim, num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_dim, embed_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, causal_mask, padding_mask):\n",
    "        # Self-attention (GPT-style)\n",
    "        h = self.ln1(x)\n",
    "        attn_out, _ = self.attn(\n",
    "            h, h, h,\n",
    "            attn_mask=causal_mask,\n",
    "            key_padding_mask=padding_mask,\n",
    "            need_weights=False\n",
    "        )\n",
    "        x = x + attn_out\n",
    "\n",
    "        # Feedforward\n",
    "        h = self.ln2(x)\n",
    "        ff_out = self.mlp(h)\n",
    "        x = x + ff_out\n",
    "\n",
    "        return x\n",
    "class DecoderOnlyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len=512,\n",
    "                 embed_dim=512, num_heads=4,\n",
    "                 num_layers=4, mlp_dim=1024, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.pos = nn.Embedding(max_len, embed_dim)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            GPTBlock(embed_dim, num_heads, mlp_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.ln_final = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, vocab_size, bias=False)\n",
    "        self.head.weight = self.embed.weight  # weight tying\n",
    "\n",
    "    def causal_mask(self, T, device):\n",
    "        mask = torch.triu(torch.ones(T, T, device=device), 1)\n",
    "        return mask.masked_fill(mask == 1, float('-inf'))\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        B, T = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        tok = self.embed(x)\n",
    "        pos = self.pos(torch.arange(T, device=device)[None, :])\n",
    "        h = tok + pos\n",
    "\n",
    "        causal = self.causal_mask(T, device)     # (T, T)\n",
    "        pad_mask = (x == 0)                      # (B, T)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, causal, pad_mask)\n",
    "\n",
    "        h = self.ln_final(h)\n",
    "        return self.head(h)                      # (B, T, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d28f38d8-8731-4171-8795-44da6aca6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, epochs=10, lr=1e-4, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    track_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        loader = tqdm(train_loader)\n",
    "        \n",
    "        for x, y, lengths in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(x, lengths)\n",
    "            \n",
    "            # Reshape for loss calculation\n",
    "            logits = logits.view(-1, logits.size(-1))\n",
    "            y = y.view(-1)\n",
    "            \n",
    "            loss = criterion(logits, y)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            track_loss.append(loss.item())\n",
    "            avg_loss = sum(track_loss[-10:]) / 10\n",
    "            loader.set_postfix(loss=avg_loss)\n",
    "            del logits\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "36b60908-11f5-444c-93ae-fd8c2568c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TokenDatasetB(train_seqs_x, train_seqs_y)\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fnB)\n",
    "\n",
    "\n",
    "# Initialize model (set vocab_size to your tokenizer's vocab size + special tokens)\n",
    "vocab_size = 16000+8  # Adjust based on your tokenizer\n",
    "model = DecoderOnlyTransformer(vocab_size=vocab_size,  num_layers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8a8ea1a7-ac2e-4361-acea-13086fd9662d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 33692672\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "47aff4d4-b6ea-49ed-83f2-6e2d656301d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/282 [00:00<?, ?it/s]/home/rohan/Desktop/berkeley/cs182/cs182/lib/python3.10/site-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.60it/s, loss=11.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Average Loss: 23.9518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.47it/s, loss=7.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Average Loss: 8.8929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.50it/s, loss=6.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Average Loss: 6.5989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.42it/s, loss=5.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Average Loss: 5.6126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.46it/s, loss=4.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Average Loss: 5.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.40it/s, loss=4.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Average Loss: 4.7846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 282/282 [00:13<00:00, 20.39it/s, loss=4.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Average Loss: 4.5774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.37it/s, loss=4.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Average Loss: 4.4252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.45it/s, loss=4.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Average Loss: 4.3080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.42it/s, loss=4.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Average Loss: 4.2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.40it/s, loss=4.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Average Loss: 4.1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.33it/s, loss=4.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Average Loss: 4.0653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.38it/s, loss=4.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Average Loss: 4.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.31it/s, loss=3.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Average Loss: 3.9410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.35it/s, loss=3.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Average Loss: 3.8842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.37it/s, loss=3.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Average Loss: 3.8330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.34it/s, loss=3.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Average Loss: 3.7831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 282/282 [00:13<00:00, 20.32it/s, loss=3.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Average Loss: 3.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.30it/s, loss=3.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Average Loss: 3.6852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 282/282 [00:13<00:00, 20.35it/s, loss=3.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Average Loss: 3.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = train_model(model, train_loader, epochs=20, lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd87460a-0f31-4f0c-800d-ff8ffb727abb",
   "metadata": {},
   "source": [
    "# get one input output pair with special tokens for later concatenation with other pairs for one sequence under max sequence length\n",
    "def getEncoding(df, i):\n",
    "    reviewtext = \"Review: \"+ df[\"reviewText\"].iloc[i]\n",
    "    rating = \"\\n Rating: \" + str(int(df[\"overall\"].iloc[i]))\n",
    "    #row = [16000] + tok.encode(reviewText, out_type=int) + [16001] + tok.encode([int(df[\"overall\"].iloc[i])], out_type = int)\n",
    "    row = [16000] + tok.encode(reviewtext, out_type = int) + tok.encode(rating, out_type = int) + [16001]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e21d8c29-ba36-41fe-9509-a107481bfbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [345, 23, 44, 99]\n",
    "kt = torch.tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "65c02368-8230-4a74-b928-61157375ed3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "dcc225f7-a78e-4020-9977-d1fb388eb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno, score = getEncodingOpen(test_df, random.randint(0,len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bbb9608b-ed31-42d0-a4cd-b94fdbe089c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19232/4078374235.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  annot = torch.tensor(anno)\n"
     ]
    }
   ],
   "source": [
    "annot = torch.tensor(anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "afdf5a43-2b53-4a28-b6d9-623da3bcd233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19232/652292005.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padded_x[0,:lens] = torch.tensor(anno)\n"
     ]
    }
   ],
   "source": [
    "lens = len(anno)\n",
    "anno_len = torch.tensor([lens])\n",
    "\n",
    "# Pad sequences\n",
    "padded_x = torch.zeros(1, 512, dtype=torch.long)\n",
    "padded_x[0,:lens] = torch.tensor(anno)\n",
    "\n",
    "padded_x = padded_x.to(device)\n",
    "anno_len = anno_len.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "be79069c-cfd2-4258-9f20-a73efae09915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8c3453a3-b20d-46b8-874f-6afb88d26fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(padded_x, anno_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "37a76155-a067-4e39-817e-3312373d71ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 16008])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9f36c7b5-4122-4c48-8bef-970b56dc5898",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenout = torch.argmax(out,dim=2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "77190548-0dfa-4912-9462-ccd4e0f5e6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3f9a6132-6236-43fc-8b02-22ea37a78894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dada6bd-507c-4bf3-90d5-53036f14bd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "db69ec8a-a371-4c5e-aec4-6cd6c47b1664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Review: I loves small.{ Rating: 16 the 160{.. a the{ it the the 2t\\' 160{ to{ the{ the to to{ with size the{ times,{{. it a 160 to{ a.{ the{ this small the{{{ these{ large{.\\' waist{{ the{{ a{ large{ 160{ing{.e{ the,, 160 160 them 160{ the{ing, a{ the{, 160 them the them, of shirts{ the{ thant,\" the{ not to my\" to 160 to 160 to the{ not, thed years 160 at is{{ pair than sizes to the toing the them is size is them{ than with, them than tot{ the them the\". with after the{ them my 160 than to.{ 160 to\"{ to. to.. to, 160 them bigger{,,\\'ing the 160 a{{{{ 160 the on{ the the. them.\\'{.{ to on the{ to. 160 160.,{{ because the the to 160 160 the{ them pants{ the the.. on than{ a the the{{ at is the{ them is, the not,{ the.{{ smalled size 160 the 160,{ always small use after{ is/ 160{ what. on the my{\" them the size to{{ is\",/\".ing at{ and\\'?{.\\'/,. size the{,{ out 160{{ 160{ 160 large the than small the than: them{ have 160 the{ 160 seem 160 love{\\' to the{. 160 and the the. 160{ it I theing the on{ the 160{, he{ theinging{{ size{ 160/ing, the it{ to.{ loved them\\',\"{ 160. it to. sizes the 160{ years, the, thaning{ on it{ the,{ 160 with to to, the, the the{, the,/{{ 160/., than to size{{{ than look\" to\" the should the them{ 160 the to of large 160 to to to it\" to them 160 to the{ 160 them to,{s{{ the{{,\\'. is a{ 160 on{{ to the{,\" the{ to{{,{{{ large{ as{\\' 160{ 160 160 160 160 fast the'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tok.decode([min(15999,to) for to in tokenout.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0ba14-4687-46de-a45c-49d702ce45e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "056021ea-c2ee-4b3b-83a1-a39e04cb3a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICLDataset(Dataset):\n",
    "    def __init__(self, df, shots, seq_len):\n",
    "        self.df = df\n",
    "        self.shots = shots\n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def getpre(self, idx, l):\n",
    "        for _ in range(10):\n",
    "            ixs = []\n",
    "            xs = []\n",
    "            for j in range(self.shots):\n",
    "                sel = idx\n",
    "                while(sel==idx):\n",
    "                    sel = random.randint(0, self.__len__() -1)\n",
    "                xs.extend(getEncoding(self.df, sel))\n",
    "            if(len(xs) + l <= seq_len):\n",
    "                return torch.LongTensor(xs)\n",
    "        raise ValueError(f\"can't fit {self.shots} examples in context\")\n",
    "                \n",
    "            \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = getEncodingOpen(self.df, idx)\n",
    "        l = len(x)\n",
    "        pre = self.getpre(idx, l)\n",
    "        icl_x = torch.cat((pre,x))\n",
    "        return icl_x, y\n",
    "\n",
    "# Padding collate function for variable length sequences\n",
    "def collate_fn_icl(batch):\n",
    "    seqs_x, y = zip(*batch)\n",
    "    lens = [len(s) for s in seqs_x]\n",
    "    max_len = max(lens)\n",
    "    \n",
    "    # Pad sequences\n",
    "    padded_x = torch.zeros(len(seqs_x), max_len, dtype=torch.long)\n",
    "    \n",
    "    for i, x in enumerate(seqs_x):\n",
    "        padded_x[i, :len(x)] = x\n",
    "    \n",
    "    return padded_x, torch.LongTensor(y), torch.LongTensor(lens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4a205d72-f62a-4c03-8f30-01030aebbc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_dataset = ICLDataset(train_df, 3, seq_len)\n",
    "icl_loader = DataLoader(icl_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn_icl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cefcec9-c47a-4681-9065-2b98bd131630",
   "metadata": {},
   "source": [
    "for batch_idx, (x, y, lengths) in enumerate(icl_loader):\n",
    "    print(\"bi\")\n",
    "    print(batch_idx)\n",
    "    print(\"x\")\n",
    "    print(x)\n",
    "    print(x.shape)\n",
    "    print(\"y\")\n",
    "    print(y)\n",
    "    print(y.shape)\n",
    "    print(\"lengths\")\n",
    "    print(lengths.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "884c4939-b40f-4f44-a047-71c0b6e6da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def israting(s):\n",
    "    bnk = [\"0\",\"1\",\"2\",\"3\",\"4\"]\n",
    "    return s in bnk\n",
    "def isnum(s):\n",
    "    bnk = [str(n) for n in range(0,20)]\n",
    "    return s in bnk\n",
    "\n",
    "def check_token_list(token_list):\n",
    "    isratings = 0\n",
    "    isnums = 0\n",
    "    for token in token_list:\n",
    "        isratings += 1 if israting(token) else 0\n",
    "        isnums += 1 if isnum(token) else 0\n",
    "    return isratings, isnums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "aaaa732b-6c79-42e0-93ee-f4bf7a3934ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode([15999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "27ce53df-96b0-4462-8eee-58e8fbf10495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c5fa459f-8429-4742-b03d-e1318ead4903",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {16000: \"<BOS>\", 16001: \"<EOS>\",16002: \"<SEP>\",16003: \"<0>\",16004: \"<1>\",16005: \"<2>\",16006: \"<3>\",16007: \"<4>\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e79e97b3-1fd2-4b1e-a994-1f23daebb889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(seq):\n",
    "    outp = \"\"\n",
    "    sofar = []\n",
    "    for i in seq:\n",
    "        if(i<=15999):\n",
    "            sofar.append(i)\n",
    "        else:\n",
    "            outp += tok.decode(sofar)\n",
    "            outp += d[i]\n",
    "    return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "755ae39c-767c-4cd6-b79a-d9f814cd9061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 191])\n",
      "tensor([16000,  7421,   292,  1955,    13,  1576,   174,     3,  1602,   288,\n",
      "           31,   208,   165, 16002, 13254,   292,  1736, 10110, 16001, 16000,\n",
      "         7421,   292,    83,   163,    75,     7,  2550,     9,    46,   106,\n",
      "           51,   492,     6,     5,    54,     4,   398,    94,   701,    64,\n",
      "            9,   127,     8,    54,    17,  2836,     3,     4,    88,  1015,\n",
      "         1192,     7,     4,   102,   137,     8,   956,    17,  1015,   586,\n",
      "           79,     3,  1831,    51,     3,  1185,   203,    33,   116,   897,\n",
      "          248,   409,     6,   129,    69,  9276,  1372,    17,    31,   732,\n",
      "            3, 16002, 13254,   292,  1736,  2301,  1974, 16001, 16000,  7421,\n",
      "          292,  3267,   973,  6245,  8655,  1535,  6757,  1200,  2609,   935,\n",
      "         1547, 11506,   808,  3317, 13971,  1073, 16002, 13254,   292,  1736,\n",
      "        14419, 16001, 16000,  7421,   292,   168,    40,   354,     6,    36,\n",
      "           40,    49,    11,   482,     6,    23,    97,    42,    27,     9,\n",
      "           27,    21,    11,     8,   876,     6,    22,    58,    59,     3,\n",
      "        16002, 13254,   292,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0], device='cuda:0')\n",
      "<BOS>Review: Sizing is WAY off. Never buying this brand again<SEP>Review: Sizing is WAY off. Never buying this brand again Rating: 16003<EOS>Review: Sizing is WAY off. Never buying this brand again Rating: 16003<BOS>Review: Sizing is WAY off. Never buying this brand again Rating: 16003 Review: Great looking shoe and appeared to be made well however, the pair I received from Sperry had to been a pair of seconds. I ordered 13b and I really got a paid of 13A . Oh well. Since there was no free return shipping, i would steer clear of this company.<SEP>Review: Sizing is WAY off. Never buying this brand again Rating: 16003 Review: Great looking shoe and appeared to be made well however, the pair I received from Sperry had to been a pair of seconds. I ordered 13b and I really got a paid of 13A . Oh well. Since there was no free return shipping, i would steer clear of this company. Rating: 16004<EOS>Review: Sizing is WAY off. Never buying this brand again Rating: 16003 Review: Great looking shoe and appeared to be made well however, the pair I received from Sperry had to been a pair of seconds. I ordered 13b and I really got a paid of 13A . Oh well. Since there was no free return shipping, i would steer clear of this company. Rating: 16004<BOS>Review: Sizing is WAY off. Never buying this brand again Rating: 16003 Review: Great looking shoe and appeared to be made well however, the pair I received from Sperry had to been a pair of seconds. I ordered 13b and I really got a paid of 13A . Oh well. Since there was no free return shipping, i would steer clear of this company. Rating: 16004 Review: HAD TO RETURN WAIST IS FINE BUT BELLY COULDNT GET AROUND IT<SEP>Review: Sizing is WAY off. Never buying this brand again Rating: 16003 Review: Great looking shoe and appeared to be made well however, the pair I received from Sperry had to been a pair of seconds. I ordered 13b and I really got a paid of 13A . Oh well. Since there was no free return shipping, i would steer clear of this company. Rating: 16004 Review: HAD TO RETURN WAIST IS FINE BUT BELLY COULDNT GET AROUND IT Rating: 16005<EOS>Review: Sizing is WAY off. Never buying this brand again Rating: 16003 Review: Great looking shoe and appeared to be made well however, the pair I received from Sperry had to been a pair of seconds. I ordered 13b and I really got a paid of 13A . Oh well. Since there was no free return shipping, i would steer clear of this company. Rating: 16004 Review: HAD TO RETURN WAIST IS FINE BUT BELLY COULDNT GET AROUND IT Rating: 16005<BOS>Review: Sizing is WAY off. Never buying this brand again Rating: 16003 Review: Great looking shoe and appeared to be made well however, the pair I received from Sperry had to been a pair of seconds. I ordered 13b and I really got a paid of 13A . Oh well. Since there was no free return shipping, i would steer clear of this company. Rating: 16004 Review: HAD TO RETURN WAIST IS FINE BUT BELLY COULDNT GET AROUND IT Rating: 16005 Review: material very stiff, not very comfortable for everyday, but if you have to have them for a uniform, they will work.<SEP>\n",
      "\n",
      "<BOS>Review: ok for a child<SEP>Review: ok for a child Rating: 16005<EOS>Review: ok for a child Rating: 16005<BOS>Review: ok for a child Rating: 16005 Review: dont trust photo, it's like wine barrel on body !<SEP>Review: ok for a child Rating: 16005 Review: dont trust photo, it's like wine barrel on body ! Rating: 16003<EOS>Review: ok for a child Rating: 16005 Review: dont trust photo, it's like wine barrel on body ! Rating: 16003<BOS>Review: ok for a child Rating: 16005 Review: dont trust photo, it's like wine barrel on body ! Rating: 16003 Review: too small and got lost in mail on return- no refund either.<SEP>Review: ok for a child Rating: 16005 Review: dont trust photo, it's like wine barrel on body ! Rating: 16003 Review: too small and got lost in mail on return- no refund either. Rating: 16003<EOS>Review: ok for a child Rating: 16005 Review: dont trust photo, it's like wine barrel on body ! Rating: 16003 Review: too small and got lost in mail on return- no refund either. Rating: 16003<BOS>Review: ok for a child Rating: 16005 Review: dont trust photo, it's like wine barrel on body ! Rating: 16003 Review: too small and got lost in mail on return- no refund either. Rating: 16003 Review: A little tight in the waist but, they fit<SEP>\n",
      "\n",
      "<BOS>Review: The shoes looked very nice and seemed to be made well. We ordered a WIDE and there is no way these are Wide-they were more narrow than a regular sized shoe, and we had to return them.<SEP>Review: The shoes looked very nice and seemed to be made well. We ordered a WIDE and there is no way these are Wide-they were more narrow than a regular sized shoe, and we had to return them. Rating: 16004<EOS>Review: The shoes looked very nice and seemed to be made well. We ordered a WIDE and there is no way these are Wide-they were more narrow than a regular sized shoe, and we had to return them. Rating: 16004<BOS>Review: The shoes looked very nice and seemed to be made well. We ordered a WIDE and there is no way these are Wide-they were more narrow than a regular sized shoe, and we had to return them. Rating: 16004 Review: I don't know where the F they got the sizing from.. I ordered an 11, my brother is a 13 and they were huge on him. Garbage<SEP>Review: The shoes looked very nice and seemed to be made well. We ordered a WIDE and there is no way these are Wide-they were more narrow than a regular sized shoe, and we had to return them. Rating: 16004 Review: I don't know where the F they got the sizing from.. I ordered an 11, my brother is a 13 and they were huge on him. Garbage Rating: 16003<EOS>Review: The shoes looked very nice and seemed to be made well. We ordered a WIDE and there is no way these are Wide-they were more narrow than a regular sized shoe, and we had to return them. Rating: 16004 Review: I don't know where the F they got the sizing from.. I ordered an 11, my brother is a 13 and they were huge on him. Garbage Rating: 16003<BOS>Review: The shoes looked very nice and seemed to be made well. We ordered a WIDE and there is no way these are Wide-they were more narrow than a regular sized shoe, and we had to return them. Rating: 16004 Review: I don't know where the F they got the sizing from.. I ordered an 11, my brother is a 13 and they were huge on him. Garbage Rating: 16003 Review: it said men's but can in woman's size, so of course didn't fit a mans foot.<SEP>Review: The shoes looked very nice and seemed to be made well. We ordered a WIDE and there is no way these are Wide-they were more narrow than a regular sized shoe, and we had to return them. Rating: 16004 Review: I don't know where the F they got the sizing from.. I ordered an 11, my brother is a 13 and they were huge on him. Garbage Rating: 16003 Review: it said men's but can in woman's size, so of course didn't fit a mans foot. Rating: 16004<EOS>Review: The shoes looked very nice and seemed to be made well. We ordered a WIDE and there is no way these are Wide-they were more narrow than a regular sized shoe, and we had to return them. Rating: 16004 Review: I don't know where the F they got the sizing from.. I ordered an 11, my brother is a 13 and they were huge on him. Garbage Rating: 16003 Review: it said men's but can in woman's size, so of course didn't fit a mans foot. Rating: 16004<BOS>Review: The shoes looked very nice and seemed to be made well. We ordered a WIDE and there is no way these are Wide-they were more narrow than a regular sized shoe, and we had to return them. Rating: 16004 Review: I don't know where the F they got the sizing from.. I ordered an 11, my brother is a 13 and they were huge on him. Garbage Rating: 16003 Review: it said men's but can in woman's size, so of course didn't fit a mans foot. Rating: 16004 Review: Fairly happy with my purchase<SEP>\n",
      "\n",
      "<BOS>Review: Shoe has a very rubbery bottom, which may be good for some, but not what I expected on a dress shoe. Leather has some imperfections that look like scratches. Wouldn't order again.<SEP>Review: Shoe has a very rubbery bottom, which may be good for some, but not what I expected on a dress shoe. Leather has some imperfections that look like scratches. Wouldn't order again. Rating: 16004<EOS>Review: Shoe has a very rubbery bottom, which may be good for some, but not what I expected on a dress shoe. Leather has some imperfections that look like scratches. Wouldn't order again. Rating: 16004<BOS>Review: Shoe has a very rubbery bottom, which may be good for some, but not what I expected on a dress shoe. Leather has some imperfections that look like scratches. Wouldn't order again. Rating: 16004 Review: It didn't fit me<SEP>Review: Shoe has a very rubbery bottom, which may be good for some, but not what I expected on a dress shoe. Leather has some imperfections that look like scratches. Wouldn't order again. Rating: 16004 Review: It didn't fit me Rating: 16004<EOS>Review: Shoe has a very rubbery bottom, which may be good for some, but not what I expected on a dress shoe. Leather has some imperfections that look like scratches. Wouldn't order again. Rating: 16004 Review: It didn't fit me Rating: 16004<BOS>Review: Shoe has a very rubbery bottom, which may be good for some, but not what I expected on a dress shoe. Leather has some imperfections that look like scratches. Wouldn't order again. Rating: 16004 Review: It didn't fit me Rating: 16004 Review: I have always worn KEDS for 45+ years. They are making then extremely cheap. I am disappointed in the way KEDS are making their products. Don't know if this are a knock off or not but i want to cry, these are not the KEDS I have grown up with or would only wear.<SEP>Review: Shoe has a very rubbery bottom, which may be good for some, but not what I expected on a dress shoe. Leather has some imperfections that look like scratches. Wouldn't order again. Rating: 16004 Review: It didn't fit me Rating: 16004 Review: I have always worn KEDS for 45+ years. They are making then extremely cheap. I am disappointed in the way KEDS are making their products. Don't know if this are a knock off or not but i want to cry, these are not the KEDS I have grown up with or would only wear. Rating: 16004<EOS>Review: Shoe has a very rubbery bottom, which may be good for some, but not what I expected on a dress shoe. Leather has some imperfections that look like scratches. Wouldn't order again. Rating: 16004 Review: It didn't fit me Rating: 16004 Review: I have always worn KEDS for 45+ years. They are making then extremely cheap. I am disappointed in the way KEDS are making their products. Don't know if this are a knock off or not but i want to cry, these are not the KEDS I have grown up with or would only wear. Rating: 16004<BOS>Review: Shoe has a very rubbery bottom, which may be good for some, but not what I expected on a dress shoe. Leather has some imperfections that look like scratches. Wouldn't order again. Rating: 16004 Review: It didn't fit me Rating: 16004 Review: I have always worn KEDS for 45+ years. They are making then extremely cheap. I am disappointed in the way KEDS are making their products. Don't know if this are a knock off or not but i want to cry, these are not the KEDS I have grown up with or would only wear. Rating: 16004 Review: These are nice but very baggy.<SEP>\n",
      "\n",
      "<BOS>Review: These pants have no tag. They look faded like they have been washed and worn more than once. If I could post a picture I would. Very disappointed. They do not even have the tag indicating the the size.<SEP>Review: These pants have no tag. They look faded like they have been washed and worn more than once. If I could post a picture I would. Very disappointed. They do not even have the tag indicating the the size. Rating: 16003<EOS>Review: These pants have no tag. They look faded like they have been washed and worn more than once. If I could post a picture I would. Very disappointed. They do not even have the tag indicating the the size. Rating: 16003<BOS>Review: These pants have no tag. They look faded like they have been washed and worn more than once. If I could post a picture I would. Very disappointed. They do not even have the tag indicating the the size. Rating: 16003 Review: I really lov the design of this watch, but this is my second try and the band is still large. I am keeping this one, because of the light up feature and design, but I do wish they had a smaller band...<SEP>Review: These pants have no tag. They look faded like they have been washed and worn more than once. If I could post a picture I would. Very disappointed. They do not even have the tag indicating the the size. Rating: 16003 Review: I really lov the design of this watch, but this is my second try and the band is still large. I am keeping this one, because of the light up feature and design, but I do wish they had a smaller band... Rating: 16006<EOS>Review: These pants have no tag. They look faded like they have been washed and worn more than once. If I could post a picture I would. Very disappointed. They do not even have the tag indicating the the size. Rating: 16003 Review: I really lov the design of this watch, but this is my second try and the band is still large. I am keeping this one, because of the light up feature and design, but I do wish they had a smaller band... Rating: 16006<BOS>Review: These pants have no tag. They look faded like they have been washed and worn more than once. If I could post a picture I would. Very disappointed. They do not even have the tag indicating the the size. Rating: 16003 Review: I really lov the design of this watch, but this is my second try and the band is still large. I am keeping this one, because of the light up feature and design, but I do wish they had a smaller band... Rating: 16006 Review: Great price for a versatile shoe! Have the back ones too and happy with both. I would recommend this shoe and would buy it gain when he needs the larger size.<SEP>Review: These pants have no tag. They look faded like they have been washed and worn more than once. If I could post a picture I would. Very disappointed. They do not even have the tag indicating the the size. Rating: 16003 Review: I really lov the design of this watch, but this is my second try and the band is still large. I am keeping this one, because of the light up feature and design, but I do wish they had a smaller band... Rating: 16006 Review: Great price for a versatile shoe! Have the back ones too and happy with both. I would recommend this shoe and would buy it gain when he needs the larger size. Rating: 16007<EOS>Review: These pants have no tag. They look faded like they have been washed and worn more than once. If I could post a picture I would. Very disappointed. They do not even have the tag indicating the the size. Rating: 16003 Review: I really lov the design of this watch, but this is my second try and the band is still large. I am keeping this one, because of the light up feature and design, but I do wish they had a smaller band... Rating: 16006 Review: Great price for a versatile shoe! Have the back ones too and happy with both. I would recommend this shoe and would buy it gain when he needs the larger size. Rating: 16007<BOS>Review: These pants have no tag. They look faded like they have been washed and worn more than once. If I could post a picture I would. Very disappointed. They do not even have the tag indicating the the size. Rating: 16003 Review: I really lov the design of this watch, but this is my second try and the band is still large. I am keeping this one, because of the light up feature and design, but I do wish they had a smaller band... Rating: 16006 Review: Great price for a versatile shoe! Have the back ones too and happy with both. I would recommend this shoe and would buy it gain when he needs the larger size. Rating: 16007 Review: This is the second watch like this that I bought. My grandchildren love them! Maybe they will be able to read a face clock instead of just digital!<SEP>\n",
      "\n",
      "<BOS>Review: Not the same as the picture. This looks like a dollar store buy.<SEP>Review: Not the same as the picture. This looks like a dollar store buy. Rating: 16003<EOS>Review: Not the same as the picture. This looks like a dollar store buy. Rating: 16003<BOS>Review: Not the same as the picture. This looks like a dollar store buy. Rating: 16003 Review: Love the shoes. They fit just right and the price was just right too!!<SEP>Review: Not the same as the picture. This looks like a dollar store buy. Rating: 16003 Review: Love the shoes. They fit just right and the price was just right too!! Rating: 16007<EOS>Review: Not the same as the picture. This looks like a dollar store buy. Rating: 16003 Review: Love the shoes. They fit just right and the price was just right too!! Rating: 16007<BOS>Review: Not the same as the picture. This looks like a dollar store buy. Rating: 16003 Review: Love the shoes. They fit just right and the price was just right too!! Rating: 16007 Review: After reading reviews and to don't miss I decided to order 36... if I lock them I wouldn't be able to sit. My last travelers from Banana are 35 and they fit loose and baggy. Also got work pants on Banana 36-32 and super comfortable and great to work.<SEP>Review: Not the same as the picture. This looks like a dollar store buy. Rating: 16003 Review: Love the shoes. They fit just right and the price was just right too!! Rating: 16007 Review: After reading reviews and to don't miss I decided to order 36... if I lock them I wouldn't be able to sit. My last travelers from Banana are 35 and they fit loose and baggy. Also got work pants on Banana 36-32 and super comfortable and great to work. Rating: 16003<EOS>Review: Not the same as the picture. This looks like a dollar store buy. Rating: 16003 Review: Love the shoes. They fit just right and the price was just right too!! Rating: 16007 Review: After reading reviews and to don't miss I decided to order 36... if I lock them I wouldn't be able to sit. My last travelers from Banana are 35 and they fit loose and baggy. Also got work pants on Banana 36-32 and super comfortable and great to work. Rating: 16003<BOS>Review: Not the same as the picture. This looks like a dollar store buy. Rating: 16003 Review: Love the shoes. They fit just right and the price was just right too!! Rating: 16007 Review: After reading reviews and to don't miss I decided to order 36... if I lock them I wouldn't be able to sit. My last travelers from Banana are 35 and they fit loose and baggy. Also got work pants on Banana 36-32 and super comfortable and great to work. Rating: 16003 Review: Same size I wear to work every day , but these were way too small<SEP>\n",
      "\n",
      "<BOS>Review: Not as comfortable as my other sauconys but still good<SEP>Review: Not as comfortable as my other sauconys but still good Rating: 16005<EOS>Review: Not as comfortable as my other sauconys but still good Rating: 16005<BOS>Review: Not as comfortable as my other sauconys but still good Rating: 16005 Review: like it, fits, comfortable<SEP>Review: Not as comfortable as my other sauconys but still good Rating: 16005 Review: like it, fits, comfortable Rating: 16006<EOS>Review: Not as comfortable as my other sauconys but still good Rating: 16005 Review: like it, fits, comfortable Rating: 16006<BOS>Review: Not as comfortable as my other sauconys but still good Rating: 16005 Review: like it, fits, comfortable Rating: 16006 Review: It's a very rough material, should stand up to heavy wear. It's ufortunate that there isn't exact sizing like jeans.<SEP>Review: Not as comfortable as my other sauconys but still good Rating: 16005 Review: like it, fits, comfortable Rating: 16006 Review: It's a very rough material, should stand up to heavy wear. It's ufortunate that there isn't exact sizing like jeans. Rating: 16004<EOS>Review: Not as comfortable as my other sauconys but still good Rating: 16005 Review: like it, fits, comfortable Rating: 16006 Review: It's a very rough material, should stand up to heavy wear. It's ufortunate that there isn't exact sizing like jeans. Rating: 16004<BOS>Review: Not as comfortable as my other sauconys but still good Rating: 16005 Review: like it, fits, comfortable Rating: 16006 Review: It's a very rough material, should stand up to heavy wear. It's ufortunate that there isn't exact sizing like jeans. Rating: 16004 Review: They are laced. they work<SEP>\n",
      "\n",
      "<BOS>Review: Good q! uality. Perfect size<SEP>Review: Good q! uality. Perfect size Rating: 16007<EOS>Review: Good q! uality. Perfect size Rating: 16007<BOS>Review: Good q! uality. Perfect size Rating: 16007 Review: In general I liked, however, despite requesting long 32, the one I always use, they were a little short, as if they were 30.<SEP>Review: Good q! uality. Perfect size Rating: 16007 Review: In general I liked, however, despite requesting long 32, the one I always use, they were a little short, as if they were 30. Rating: 16005<EOS>Review: Good q! uality. Perfect size Rating: 16007 Review: In general I liked, however, despite requesting long 32, the one I always use, they were a little short, as if they were 30. Rating: 16005<BOS>Review: Good q! uality. Perfect size Rating: 16007 Review: In general I liked, however, despite requesting long 32, the one I always use, they were a little short, as if they were 30. Rating: 16005 Review: The interface is easy to read and the watch is not complicated. The face of the watch is both thin and not too large which is great because I have small arms.<SEP>Review: Good q! uality. Perfect size Rating: 16007 Review: In general I liked, however, despite requesting long 32, the one I always use, they were a little short, as if they were 30. Rating: 16005 Review: The interface is easy to read and the watch is not complicated. The face of the watch is both thin and not too large which is great because I have small arms. Rating: 16006<EOS>Review: Good q! uality. Perfect size Rating: 16007 Review: In general I liked, however, despite requesting long 32, the one I always use, they were a little short, as if they were 30. Rating: 16005 Review: The interface is easy to read and the watch is not complicated. The face of the watch is both thin and not too large which is great because I have small arms. Rating: 16006<BOS>Review: Good q! uality. Perfect size Rating: 16007 Review: In general I liked, however, despite requesting long 32, the one I always use, they were a little short, as if they were 30. Rating: 16005 Review: The interface is easy to read and the watch is not complicated. The face of the watch is both thin and not too large which is great because I have small arms. Rating: 16006 Review: These were at least 1.5 inches too small in the waist. Length was accurate.<SEP>\n",
      "\n",
      "========================\n",
      "torch.Size([8, 191])\n",
      "Review: I is not too. I Never more is.. Rating: 1600<EOS>Review: I is not too. I Never more is.. Rating: 1600<BOS>Review: I is not too. I Never more is.. Rating: 1600 Review: The quality for, have to small a. made, I fabric of have. the' the wear wearing little of the or<SEP>Review: I is not too. I Never more is.. Rating: 1600 Review: The quality for, have to small a. made, I fabric of have. the' the wear wearing little of the or have the and and the have like it size for the 13.,<SEP>Review: I is not too. I Never more is.. Rating: 1600 Review: The quality for, have to small a. made, I fabric of have. the' the wear wearing little of the or have the and and the have like it size for the 13., well made<SEP>Review: I is not too. I Never more is.. Rating: 1600 Review: The quality for, have to small a. made, I fabric of have. the' the wear wearing little of the or have the and and the have like it size for the 13., well made I was not arch. them. but have have. clear the is it<SEP>Review: I is not too. I Never more is.. Rating: 1600 Review: The quality for, have to small a. made, I fabric of have. the' the wear wearing little of the or have the and and the have like it size for the 13., well made I was not arch. them. but have have. clear the is it Rating: 16004<EOS>Review: I is not too. I Never more is.. Rating: 1600 Review: The quality for, have to small a. made, I fabric of have. the' the wear wearing little of the or have the and and the have like it size for the 13., well made I was not arch. them. but have have. clear the is it Rating: 16004<BOS>Review: I is not too. I Never more is.. Rating: 1600 Review: The quality for, have to small a. made, I fabric of have. the' the wear wearing little of the or have the and and the have like it size for the 13., well made I was not arch. them. but have have. clear the is it Rating: 16004 Review: I HAD,.. IS. the them.LY.. time. is Rating: 16007<EOS>Review: I is not too. I Never more is.. Rating: 1600 Review: The quality for, have to small a. made, I fabric of have. the' the wear wearing little of the or have the and and the have like it size for the 13., well made I was not arch. them. but have have. clear the is it Rating: 16004 Review: I HAD,.. IS. the them.LY.. time. is Rating: 16007<BOS>Review: I is not too. I Never more is.. Rating: 1600 Review: The quality for, have to small a. made, I fabric of have. the' the wear wearing little of the or have the and and the have like it size for the 13., well made I was not arch. them. but have have. clear the is it Rating: 16004 Review: I HAD,.. IS. the them.LY.. time. is Rating: 16007 Review: I. comfortable and I the comfortable. the everyday but I I have to be to. the good. and are be pants<SEP>\n",
      "\n",
      "Review: I<SEP>Review: I a little. Rating: 16005<EOS>Review: I a little. Rating: 16005<BOS>Review: I a little. Rating: 16005 Review: I' fit trust. but.s a the toe and the.<SEP>Review: I a little. Rating: 16005 Review: I' fit trust. but.s a the toe and the. Rating: 1600<EOS>Review: I a little. Rating: 16005 Review: I' fit trust. but.s a the toe and the. Rating: 1600<BOS>Review: I a little. Rating: 16005 Review: I' fit trust. but.s a the toe and the. Rating: 1600 Review: I small. it to a the. the themshirt support..<SEP>Review: I a little. Rating: 16005 Review: I' fit trust. but.s a the toe and the. Rating: 1600 Review: I small. it to a the. the themshirt support.. Rating: 1600<EOS>Review: I a little. Rating: 16005 Review: I' fit trust. but.s a the toe and the. Rating: 1600 Review: I small. it to a the. the themshirt support.. Rating: 1600<BOS>Review: I a little. Rating: 16005 Review: I' fit trust. but.s a the toe and the. Rating: 1600 Review: I small. it to a the. the themshirt support.. Rating: 1600 Review: I little small. the waist and the I are. Rating: 16.<SEP>Review: I a little. Rating: 16005 Review: I' fit trust. but.s a the toe and the. Rating: 1600 Review: I small. it to a the. the themshirt support.. Rating: 1600 Review: I little small. the waist and the I are. Rating: 16....<SEP>Review: I a little. Rating: 16005 Review: I' fit trust. but.s a the toe and the. Rating: 1600 Review: I small. it to a the. the themshirt support.. Rating: 1600 Review: I little small. the waist and the I are. Rating: 16..... the<SEP>Review: I a little. Rating: 16005 Review: I' fit trust. but.s a the toe and the. Rating: 1600 Review: I small. it to a the. the themshirt support.. Rating: 1600 Review: I little small. the waist and the I are. Rating: 16..... the and tot,,. is... I I.... is.ing,.. I.\",\"...,<SEP>Review: I a little. Rating: 16005 Review: I' fit trust. but.s a the toe and the. Rating: 1600 Review: I small. it to a the. the themshirt support.. Rating: 1600 Review: I little small. the waist and the I are. Rating: 16..... the and tot,,. is... I I.... is.ing,.. I.\",\"...,, the.. to,... the... years and... the them.. to the,... loves.. the.. I,.\" iss, the\"..\". and... out, the on.. is the'<SEP>Review: I a little. Rating: 16005 Review: I' fit trust. but.s a the toe and the. Rating: 1600 Review: I small. it to a the. the themshirt support.. Rating: 1600 Review: I little small. the waist and the I are. Rating: 16..... the and tot,,. is... I I.... is.ing,.. I.\",\"...,, the.. to,... the... years and... the them.. to the,... loves.. the.. I,.\" iss, the\"..\". and... out, the on.. is the'...,..... is<SEP>\n",
      "\n",
      "Review: I color are very comfortable. the well the a..<SEP>Review: I color are very comfortable. the well the a.. We a little is the is not longer I pants the isshirts are too.. the bit size.. and the' to wear them.<SEP>Review: I color are very comfortable. the well the a.. We a little is the is not longer I pants the isshirts are too.. the bit size.. and the' to wear them. Rating: 1600054<EOS>Review: I color are very comfortable. the well the a.. We a little is the is not longer I pants the isshirts are too.. the bit size.. and the' to wear them. Rating: 1600054<BOS>Review: I color are very comfortable. the well the a.. We a little is the is not longer I pants the isshirts are too.. the bit size.. and the' to wear them. Rating: 1600054 Review: I have't wear I it same F are the waist. the<SEP>Review: I color are very comfortable. the well the a.. We a little is the is not longer I pants the isshirts are too.. the bit size.. and the' to wear them. Rating: 1600054 Review: I have't wear I it same F are the waist. the<SEP>Review: I color are very comfortable. the well the a.. We a little is the is not longer I pants the isshirts are too.. the bit size.. and the' to wear them. Rating: 1600054 Review: I have't wear I it same F are the waist. the have the excellent and feet. not little and the are too, the.<SEP>Review: I color are very comfortable. the well the a.. We a little is the is not longer I pants the isshirts are too.. the bit size.. and the' to wear them. Rating: 1600054 Review: I have't wear I it same F are the waist. the have the excellent and feet. not little and the are too, the.. Rating: 1600<EOS>Review: I color are very comfortable. the well the a.. We a little is the is not longer I pants the isshirts are too.. the bit size.. and the' to wear them. Rating: 1600054 Review: I have't wear I it same F are the waist. the have the excellent and feet. not little and the are too, the.. Rating: 1600<BOS>Review: I color are very comfortable. the well the a.. We a little is the is not longer I pants the isshirts are too.. the bit size.. and the' to wear them. Rating: 1600054 Review: I have't wear I it same F are the waist. the have the excellent and feet. not little and the are too, the.. Rating: 1600 Review: I was they's not it' the's not. I much the I's fit well little..<SEP>Review: I color are very comfortable. the well the a.. We a little is the is not longer I pants the isshirts are too.. the bit size.. and the' to wear them. Rating: 1600054 Review: I have't wear I it same F are the waist. the have the excellent and feet. not little and the are too, the.. Rating: 1600 Review: I was they's not it' the's not. I much the I's fit well little.. Rating: 16004<EOS>Review: I color are very comfortable. the well the a.. We a little is the is not longer I pants the isshirts are too.. the bit size.. and the' to wear them. Rating: 1600054 Review: I have't wear I it same F are the waist. the have the excellent and feet. not little and the are too, the.. Rating: 1600 Review: I was they's not it' the's not. I much the I's fit well little.. Rating: 16004<BOS>Review: I color are very comfortable. the well the a.. We a little is the is not longer I pants the isshirts are too.. the bit size.. and the' to wear them. Rating: 1600054 Review: I have't wear I it same F are the waist. the have the excellent and feet. not little and the are too, the.. Rating: 1600 Review: I was they's not it' the's not. I much the I's fit well little.. Rating: 16004 Review: I not large with the size. Rating: 16 to them. it and it 30..\"..,....., to...<SEP>\n",
      "\n",
      "Review: I is a size nice of. the is may. quality the reason the I a I have. the little..<SEP>Review: I is a size nice of. the is may. quality the reason the I a I have. the little.. is size of I I like I the<SEP>Review: I is a size nice of. the is may. quality the reason the I a I have. the little.. is size of I I like I the thet even the.<SEP>Review: I is a size nice of. the is may. quality the reason the I a I have. the little.. is size of I I like I the thet even the. Rating: 160054<EOS>Review: I is a size nice of. the is may. quality the reason the I a I have. the little.. is size of I I like I the thet even the. Rating: 160054<BOS>Review: I is a size nice of. the is may. quality the reason the I a I have. the little.. is size of I I like I the thet even the. Rating: 160054 Review: 16 is's like.. Rating: 16004<EOS>Review: I is a size nice of. the is may. quality the reason the I a I have. the little.. is size of I I like I the thet even the. Rating: 160054 Review: 16 is's like.. Rating: 16004<BOS>Review: I is a size nice of. the is may. quality the reason the I a I have. the little.. is size of I I like I the thet even the. Rating: 160054 Review: 16 is's like.. Rating: 16004 Review: I have a. them and me shirts I.<SEP>Review: I is a size nice of. the is may. quality the reason the I a I have. the little.. is size of I I like I the thet even the. Rating: 160054 Review: 16 is's like.. Rating: 16004 Review: I have a. them and me shirts I. are not the the small. I have a. the waist too. not it pants. I't know what I for very little- the the buy the bought to wear. and are not the same. have the to. the so be is.<SEP>Review: I is a size nice of. the is may. quality the reason the I a I have. the little.. is size of I I like I the thet even the. Rating: 160054 Review: 16 is's like.. Rating: 16004 Review: I have a. them and me shirts I. are not the the small. I have a. the waist too. not it pants. I't know what I for very little- the the buy the bought to wear. and are not the same. have the to. the so be is. Rating: 160054<EOS>Review: I is a size nice of. the is may. quality the reason the I a I have. the little.. is size of I I like I the thet even the. Rating: 160054 Review: 16 is's like.. Rating: 16004 Review: I have a. them and me shirts I. are not the the small. I have a. the waist too. not it pants. I't know what I for very little- the the buy the bought to wear. and are not the same. have the to. the so be is. Rating: 160054<BOS>Review: I is a size nice of. the is may. quality the reason the I a I have. the little.. is size of I I like I the thet even the. Rating: 160054 Review: 16 is's like.. Rating: 16004 Review: I have a. them and me shirts I. are not the the small. I have a. the waist too. not it pants. I't know what I for very little- the the buy the bought to wear. and are not the same. have the to. the so be is. Rating: 160054 Review: These are not, the good.<SEP>Review: I is a size nice of. the is may. quality the reason the I a I have. the little.. is size of I I like I the thet even the. Rating: 160054 Review: 16 is's like.. Rating: 16004 Review: I have a. them and me shirts I. are not the the small. I have a. the waist too. not it pants. I't know what I for very little- the the buy the bought to wear. and are not the same. have the to. the so be is. Rating: 160054 Review: These are not, the good. Rating: 16. I. with than... the.. and<SEP>\n",
      "\n",
      "Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have<SEP>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed.<SEP>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is<SEP>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600<EOS>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600<BOS>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600 Review: I have nice,. same I the product. but I is not feet pair try the same. not too.<SEP>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600 Review: I have nice,. same I the product. but I is not feet pair try the same. not too. have not the is I I it the same weight.. I. and I was not I are to pair. is<SEP>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600 Review: I have nice,. same I the product. but I is not feet pair try the same. not too. have not the is I I it the same weight.. I. and I was not I are to pair. is Rating: 1606<EOS>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600 Review: I have nice,. same I the product. but I is not feet pair try the same. not too. have not the is I I it the same weight.. I. and I was not I are to pair. is Rating: 1606<BOS>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600 Review: I have nice,. same I the product. but I is not feet pair try the same. not too. have not the is I I it the same weight.. I. and I was not I are to pair. is Rating: 1606 Review: I product. the little..<SEP>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600 Review: I have nice,. same I the product. but I is not feet pair try the same. not too. have not the is I I it the same weight.. I. and I was not I are to pair. is Rating: 1606 Review: I product. the little.. to same. I small the with the the<SEP>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600 Review: I have nice,. same I the product. but I is not feet pair try the same. not too. have not the is I I it the same weight.. I. and I was not I are to pair. is Rating: 1606 Review: I product. the little.. to same. I small the with the the have have them is. I be again is is I' to time than is<SEP>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600 Review: I have nice,. same I the product. but I is not feet pair try the same. not too. have not the is I I it the same weight.. I. and I was not I are to pair. is Rating: 1606 Review: I product. the little.. to same. I small the with the the have have them is. I be again is is I' to time than is Rating: 16005<EOS>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600 Review: I have nice,. same I the product. but I is not feet pair try the same. not too. have not the is I I it the same weight.. I. and I was not I are to pair. is Rating: 1606 Review: I product. the little.. to same. I small the with the the have have them is. I be again is is I' to time than is Rating: 16005<BOS>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600 Review: I have nice,. same I the product. but I is not feet pair try the same. not too. have not the is I I it the same weight.. I. and I was not I are to pair. is Rating: 1606 Review: I product. the little.. to same. I small the with the the have have them is. I be again is is I' to time than is Rating: 16005 Review: I is not same pair. a is I have it<SEP>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600 Review: I have nice,. same I the product. but I is not feet pair try the same. not too. have not the is I I it the same weight.. I. and I was not I are to pair. is Rating: 1606 Review: I product. the little.. to same. I small the with the the have have them is. I be again is is I' to time than is Rating: 16005 Review: I is not same pair. a is I have it husband on the.<SEP>Review: I are are beent. I are great and a are a worn them the them like I. I you have not the pair. have have disappointed. are not the get to first tag. them same first is Rating: 1600 Review: I have nice,. same I the product. but I is not feet pair try the same. not too. have not the is I I it the same weight.. I. and I was not I are to pair. is Rating: 1606 Review: I product. the little.. to same. I small the with the the have have them is. I be again is is I' to time than is Rating: 16005 Review: I is not same pair. a is I have it husband on the. the are not. to be the little., of the to is<SEP>\n",
      "\n",
      "Review: I sure first as the size. I is so it little and and. It Rating: 16003<EOS>Review: I sure first as the size. I is so it little and and. It Rating: 16003<BOS>Review: I sure first as the size. I is so it little and and. It Rating: 16003 Review: I the material, I are. too. the quality is not too. small<SEP>Review: I sure first as the size. I is so it little and and. It Rating: 16003 Review: I the material, I are. too. the quality is not too. small Rating: 16005<EOS>Review: I sure first as the size. I is so it little and and. It Rating: 16003 Review: I the material, I are. too. the quality is not too. small Rating: 16005<BOS>Review: I sure first as the size. I is so it little and and. It Rating: 16003 Review: I the material, I are. too. the quality is not too. small Rating: 16005 Review: I the the I the small't fit. have to return. waist<SEP>Review: I sure first as the size. I is so it little and and. It Rating: 16003 Review: I the material, I are. too. the quality is not too. small Rating: 16005 Review: I the the I the small't fit. have to return. waist I have the.''m have the to be to<SEP>Review: I sure first as the size. I is so it little and and. It Rating: 16003 Review: I the material, I are. too. the quality is not too. small Rating: 16005 Review: I the the I the small't fit. have to return. waist I have the.''m have the to be to son long to and the was very\" it are.. I.<SEP>Review: I sure first as the size. I is so it little and and. It Rating: 16003 Review: I the material, I are. too. the quality is not too. small Rating: 16005 Review: I the the I the small't fit. have to return. waist I have the.''m have the to be to son long to and the was very\" it are.. I. the the.. the.\" the the comfortable. the. the.<SEP>Review: I sure first as the size. I is so it little and and. It Rating: 16003 Review: I the material, I are. too. the quality is not too. small Rating: 16005 Review: I the the I the small't fit. have to return. waist I have the.''m have the to be to son long to and the was very\" it are.. I. the the.. the.\" the the comfortable. the. the. Rating: 1600<EOS>Review: I sure first as the size. I is so it little and and. It Rating: 16003 Review: I the material, I are. too. the quality is not too. small Rating: 16005 Review: I the the I the small't fit. have to return. waist I have the.''m have the to be to son long to and the was very\" it are.. I. the the.. the.\" the the comfortable. the. the. Rating: 1600<BOS>Review: I sure first as the size. I is so it little and and. It Rating: 16003 Review: I the material, I are. too. the quality is not too. small Rating: 16005 Review: I the the I the small't fit. have to return. waist I have the.''m have the to be to son long to and the was very\" it are.. I. the the.. the.\" the the comfortable. the. the. Rating: 1600 Review: I size. have them the. time I, but the were too to small. Rating: 16. the. to...... to.<SEP>\n",
      "\n",
      "Review: I as soon as I usual pants I and I too quality Rating: 16005<EOS>Review: I as soon as I usual pants I and I too quality Rating: 16005<BOS>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606<EOS>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606<BOS>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it<SEP>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it iss the<SEP>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it iss the\" wear. to I is's want exact. it.<SEP>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it iss the\" wear. to I is's want exact. it. Rating: 160034<EOS>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it iss the\" wear. to I is's want exact. it. Rating: 160034<BOS>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it iss the\" wear. to I is's want exact. it. Rating: 160034 Review: I are not the<SEP>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it iss the\" wear. to I is's want exact. it. Rating: 160034 Review: I are not the are pants Rating: 16.sing,<SEP>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it iss the\" wear. to I is's want exact. it. Rating: 160034 Review: I are not the are pants Rating: 16.sing, the the......ing. and.,...\"... Iing.. them.s. than..s..\",...<SEP>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it iss the\" wear. to I is's want exact. it. Rating: 160034 Review: I are not the are pants Rating: 16.sing, the the......ing. and.,...\"... Iing.. them.s. than..s..\",..., it.. nots.,....s..<SEP>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it iss the\" wear. to I is's want exact. it. Rating: 160034 Review: I are not the are pants Rating: 16.sing, the the......ing. and.,...\"... Iing.. them.s. than..s..\",..., it.. nots.,....s..<SEP>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it iss the\" wear. to I is's want exact. it. Rating: 160034 Review: I are not the are pants Rating: 16.sing, the the......ing. and.,...\"... Iing.. them.s. than..s..\",..., it.. nots.,....s..,. than.., to<SEP>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it iss the\" wear. to I is's want exact. it. Rating: 160034 Review: I are not the are pants Rating: 16.sing, the the......ing. and.,...\"... Iing.. them.s. than..s..\",..., it.. nots.,....s..,. than.., to,<SEP>Review: I as soon as I usual pants I and I too quality Rating: 16005 Review: I the is I good and. Rating: 1606 Review: The iss very little well. is but have,. return duty it iss the\" wear. to I is's want exact. it. Rating: 160034 Review: I are not the are pants Rating: 16.sing, the the......ing. and.,...\"... Iing.. them.s. than..s..\",..., it.. nots.,....s..,. than.., to,s. well. and. the.,s,...<SEP>\n",
      "\n",
      "Review: I quality,<SEP>Review: I quality,, to<SEP>Review: I quality,, to for. Rating: 16007<EOS>Review: I quality,, to for. Rating: 16007<BOS>Review: I quality,, to for. Rating: 16007 Review: I my general have the and the butespiteespite I the, I reviews I have been it but are not little small. and expected I are not shirts<SEP>Review: I quality,, to for. Rating: 16007 Review: I my general have the and the butespiteespite I the, I reviews I have been it but are not little small. and expected I are not shirts Rating: 1600<EOS>Review: I quality,, to for. Rating: 16007 Review: I my general have the and the butespiteespite I the, I reviews I have been it but are not little small. and expected I are not shirts Rating: 1600<BOS>Review: I quality,, to for. Rating: 16007 Review: I my general have the and the butespiteespite I the, I reviews I have been it but are not little small. and expected I are not shirts Rating: 1600 Review: I fabric is the to wear the I waist. not the.<SEP>Review: I quality,, to for. Rating: 16007 Review: I my general have the and the butespiteespite I the, I reviews I have been it but are not little small. and expected I are not shirts Rating: 1600 Review: I fabric is the to wear the I waist. not the. shoes is the same is very shoes, the the big. is the. the have been..<SEP>Review: I quality,, to for. Rating: 16007 Review: I my general have the and the butespiteespite I the, I reviews I have been it but are not little small. and expected I are not shirts Rating: 1600 Review: I fabric is the to wear the I waist. not the. shoes is the same is very shoes, the the big. is the. the have been.. Rating: 1606<EOS>Review: I quality,, to for. Rating: 16007 Review: I my general have the and the butespiteespite I the, I reviews I have been it but are not little small. and expected I are not shirts Rating: 1600 Review: I fabric is the to wear the I waist. not the. shoes is the same is very shoes, the the big. is the. the have been.. Rating: 1606<BOS>Review: I quality,, to for. Rating: 16007 Review: I my general have the and the butespiteespite I the, I reviews I have been it but are not little small. and expected I are not shirts Rating: 1600 Review: I fabric is the to wear the I waist. not the. shoes is the same is very shoes, the the big. is the. the have been.. Rating: 1606 Review: I are too the 2. too small. the size is<SEP>Review: I quality,, to for. Rating: 16007 Review: I my general have the and the butespiteespite I the, I reviews I have been it but are not little small. and expected I are not shirts Rating: 1600 Review: I fabric is the to wear the I waist. not the. shoes is the same is very shoes, the the big. is the. the have been.. Rating: 1606 Review: I are too the 2. too small. the size is is not.<SEP>\n",
      "\n",
      "['.', '.', '.', '.', '16', '.', '.', '.']\n",
      "[2, 3, 3, 2, 4, 0, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "num = 0\n",
    "ratings = 0\n",
    "correct = 0\n",
    "for batch_idx, (x, y, lengths) in enumerate(icl_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    pred_logits = model(x,lengths)\n",
    "    print(x.shape)\n",
    "    print(x[0])\n",
    "    for sequence in x:\n",
    "        print(decode_seq(sequence.tolist()))\n",
    "        print()\n",
    "    print(\"========================\")\n",
    "    pred_tokens = torch.argmax(pred_logits,dim=2)\n",
    "    pred_tokens = pred_tokens.to('cpu')\n",
    "    pred_last_token = pred_tokens[:,-1].tolist()\n",
    "    print(pred_tokens.shape)\n",
    "    for sequence in pred_tokens:\n",
    "        print(decode_seq(sequence.tolist()))\n",
    "        print()\n",
    "    pred_scores = [tok.decode([token]) for token in pred_last_token]\n",
    "    print(pred_scores)\n",
    "    print(y.tolist())\n",
    "    tot += len(y)\n",
    "    for t in range(len(y)):\n",
    "        correct += 1 if pred_scores[t] == str(y[t]) else 0\n",
    "    isratings, isnums = check_token_list(pred_scores)\n",
    "    num += isnums\n",
    "    ratings += isratings\n",
    "    torch.cuda.empty_cache()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f502f9f4-9814-46d8-9f57-75d87a636bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot:  8\n",
      "num:  1\n",
      "ratings:  1\n",
      "correct:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"tot: \", tot)\n",
    "print(\"num: \", num)\n",
    "print(\"ratings: \", ratings)\n",
    "print(\"correct: \", correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68778e4c-f65d-426b-8099-ac08645be7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
