{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6325cc0a-faad-415f-b768-e8ff3ae59d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: amazon_reviews.txt\n",
      "  input_format: \n",
      "  model_prefix: amazon_reviews\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 16000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: amazon_reviews.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 112032 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=15424622\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=95\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 112032 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=8665450\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 83355 seed sentencepieces\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 112032\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 90740\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 90740 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=35198 obj=10.0011 num_tokens=205491 num_tokens/piece=5.83814\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=30303 obj=7.84363 num_tokens=207362 num_tokens/piece=6.84295\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=22723 obj=7.80598 num_tokens=215430 num_tokens/piece=9.4807\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=22710 obj=7.79839 num_tokens=215870 num_tokens/piece=9.5055\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=17599 obj=7.83138 num_tokens=227650 num_tokens/piece=12.9354\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=17598 obj=7.82446 num_tokens=227655 num_tokens/piece=12.9364\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: amazon_reviews.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: amazon_reviews.vocab\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "file = \"amazon_review.csv\"\n",
    "\n",
    "data = pd.read_csv(file).dropna(ignore_index=True)\n",
    "data['overall'] = data[\"overall\"] - 1\n",
    "\n",
    "vocab_size = 16000\n",
    "seq_len = 512\n",
    "pad_token = 16008\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='amazon_reviews.txt',\n",
    "    model_prefix='amazon_reviews',\n",
    "    vocab_size=vocab_size,\n",
    "    model_type='unigram',\n",
    "    character_coverage=1.0\n",
    ")\n",
    "\n",
    "tok = spm.SentencePieceProcessor(model_file='amazon_reviews.model')\n",
    "\n",
    "filter_ = 1\n",
    "\n",
    "ls  = [len(tok.encode(i, out_type=int)) for i in data[\"reviewText\"]]\n",
    "\n",
    "data[\"lengths\"] = ls\n",
    "\n",
    "data_trunc = data[data[\"lengths\"]<=30]\n",
    "\n",
    "v = data_trunc[\"overall\"].value_counts()\n",
    "\n",
    "balanced_data = (\n",
    "    data_trunc.groupby(\"overall\")\n",
    "      .sample(n=min(v), random_state=42)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "len(balanced_data)\n",
    "\n",
    "df_shuffled = balanced_data.sample(frac=filter_, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split the shuffled DataFrame\n",
    "train_size = 0.8\n",
    "train_df = df_shuffled.sample(frac=train_size, random_state=42).reset_index(drop=True)\n",
    "test_df = df_shuffled.drop(train_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "81bde877-51c4-416f-a49f-a446afd66bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train df:  9200\n",
      "len test df:  2300\n"
     ]
    }
   ],
   "source": [
    "print(\"len train df: \", len(train_df))\n",
    "print(\"len test df: \", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4fe9bc00-5382-476c-8d6a-37d37c8d6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one input output pair with special tokens for later concatenation with other pairs for one sequence under max sequence length\n",
    "def getEncodingOpen(df, i):\n",
    "    reviewtext = \"Review: \"+ df[\"reviewText\"].iloc[i]\n",
    "    rating = \"Rating: \" \n",
    "    #row = [16000] + tok.encode(reviewText, out_type=int) + [16001] + tok.encode([int(df[\"overall\"].iloc[i])], out_type = int)\n",
    "    row = [16000] + tok.encode(reviewtext, out_type = int) + [16002] + tok.encode(rating, out_type = int)\n",
    "    correct_output_rating = int(df[\"overall\"].iloc[i])\n",
    "    row = torch.LongTensor(row)\n",
    "    correct_output_rating = torch.LongTensor([correct_output_rating])\n",
    "    return row, correct_output_rating\n",
    "# get one input output pair with special tokens for later concatenation with other pairs for one sequence under max sequence length\n",
    "def getEncoding(df, i):\n",
    "    reviewtext = \"Review: \"+ df[\"reviewText\"].iloc[i]\n",
    "    rating = \"Rating: \" #+ str(int(df[\"overall\"].iloc[i]))\n",
    "    score = int(df[\"overall\"].iloc[i])\n",
    "    row = [16000] + tok.encode(reviewtext, out_type = int) + [16002] + tok.encode(rating, out_type = int) +[score+16003]+ [16001]\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "36d89abc-9f62-47ef-a2fa-9d3d372664a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {16000: \"<BOS>\", 16001: \"<EOS>\",16002: \"<SEP>\",16003: \"<0>\",16004: \"<1>\",16005: \"<2>\",16006: \"<3>\",16007: \"<4>\", 16008: \"PAD\"}\n",
    "\n",
    "def decode_seq(seq):\n",
    "    outp = \"\"\n",
    "    sofar = []\n",
    "    for i in seq:\n",
    "        if(i<=15999):\n",
    "            sofar.append(i)\n",
    "        else:\n",
    "            outp += tok.decode(sofar)\n",
    "            outp += d[i]\n",
    "            sofar = []\n",
    "    outp += tok.decode(sofar)\n",
    "    return outp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6c4e1c26-7e3b-4e68-8cf0-30628b15dc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS>Review: The legs are to long. Ordered a 30\" inseam. A person with a 33\" inseam could wear these with no problem.<SEP>Rating:<2><EOS>'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq(getEncoding(train_df, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e261a40-3aab-46fa-a6dd-6adc45c8f8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"overall\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "63e09b6f-98e0-41bc-8f7c-1a9f65f7122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac402251-1edf-4d2f-bbec-c97bfdae231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getShiftSeq(df_t, max_seq=1024):\n",
    "    seqs_x = []\n",
    "    seqs_y = []\n",
    "    seqs = []\n",
    "    c = []\n",
    "    for i in range(len(df_t)):\n",
    "        row = getEncoding(df_t, i)\n",
    "        if len(c) + len(row) > max_seq +1:\n",
    "            seqs_x.append(c[:-1])\n",
    "            seqs_y.append(c[1:])\n",
    "            seqs.append(c)\n",
    "            c = []\n",
    "        c.extend(row)\n",
    "    return seqs_x, seqs_y, seqs\n",
    "\n",
    "train_seqs_x, train_seqs_y, train_seqs = getShiftSeq(train_df, max_seq=seq_len)\n",
    "test_seqs_x, test_seqs_y, test_seqs = getShiftSeq(test_df, max_seq=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2e53f0d4-f49d-446b-8487-139d77e6c14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_seqs_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "081e32ee-e1bb-4647-95fb-7740cfbe50bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6f7c6b0-9afd-4c15-95cf-17d1bb41de8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good products, but they have become complete crap.<SEP>Rating:<0><EOS>'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq(train_seqs[0][-15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "26940807-a051-484c-91a4-8a17acb2ffce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[238, 47, 686, 6, 23, 22, 27, 1097, 2032, 2912, 3, 16002, 13254, 292, 16003]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seqs_x[0][-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06a05b5f-994c-4ccf-aedb-7469638b3902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47, 686, 6, 23, 22, 27, 1097, 2032, 2912, 3, 16002, 13254, 292, 16003, 16001]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seqs[0][-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "39283dd5-fa89-40ad-8261-587122857b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDatasetB(Dataset):\n",
    "    def __init__(self, seqs_x, seqs_y):\n",
    "        self.seqs_x = seqs_x\n",
    "        self.seqs_y = seqs_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.seqs_x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.seqs_x[idx]), torch.LongTensor(self.seqs_y[idx])\n",
    "\n",
    "# Padding collate function for variable length sequences\n",
    "def collate_fnB(batch):\n",
    "    seqs_x, seqs_y = zip(*batch)\n",
    "    lens = [len(s) for s in seqs_x]\n",
    "    max_len = max(lens)\n",
    "    \n",
    "    # Pad sequences\n",
    "    padded_x = torch.zeros(len(seqs_x), max_len, dtype=torch.long) + pad_token\n",
    "    padded_y = torch.zeros(len(seqs_y), max_len, dtype=torch.long) + pad_token\n",
    "    \n",
    "    for i, (x, y) in enumerate(zip(seqs_x, seqs_y)):\n",
    "        padded_x[i, :len(x)] = x\n",
    "        padded_y[i, :len(y)] = y\n",
    "    \n",
    "    return padded_x, padded_y, torch.LongTensor(lens)\n",
    "\n",
    "dataset = TokenDatasetB(train_seqs_x, train_seqs_y)\n",
    "train_loader = DataLoader(dataset, batch_size=5, shuffle=True, collate_fn=collate_fnB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d463056-66fe-4da7-9128-e3e7f7bb7e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi\n",
      "0\n",
      "x\n",
      "torch.Size([5, 504])\n",
      "[16000, 7421, 292, 70, 193, 967, 23, 31, 13, 316, 36, 11, 420, 73, 3, 1511, 15, 65, 567, 239, 73, 4, 41, 14, 3, 3, 16002, 13254, 292, 16004, 16001, 16000, 7421, 292, 567, 16002, 13254, 292, 16004, 16001, 16000, 7421, 292, 931, 937, 11, 89, 16002, 13254, 292, 16006, 16001, 16000, 7421, 292, 40, 49, 16002, 13254, 292, 16006, 16001, 16000, 7421, 292, 412, 681, 35, 4, 1451, 5, 981, 6, 4, 944, 8, 1610, 28, 5, 453, 25, 2550, 9, 86, 43, 530, 1431, 85, 778, 530, 1450, 884, 296, 16002, 13254, 292, 16003, 16001, 16000, 7421, 292, 336, 55, 43, 192, 98, 701, 7, 823, 57, 38, 53, 3, 16002, 13254, 292, 16007, 16001, 16000, 7421, 292, 147, 5703, 7, 24, 19, 116, 2065, 3, 45, 41, 51, 7, 294, 51, 3, 4, 58, 162, 91, 5703, 6, 22, 19, 150, 52, 883, 153, 124, 16002, 13254, 292, 16006, 16001, 16000, 7421, 292, 188, 4690, 1993, 676, 6518, 9263, 1200, 1073, 10, 423, 1155, 1456, 3312, 3933, 1338, 8014, 4, 3934, 3780, 3973, 9092, 1722, 3105, 124, 16002, 13254, 292, 16004, 16001, 16000, 7421, 292, 4, 102, 43, 31, 104, 23, 5, 549, 245, 894, 6, 4, 27, 88, 8, 804, 16002, 13254, 292, 16005, 16001, 16000, 7421, 292, 15822, 3, 8650, 15, 65, 17, 18, 1461, 339, 16, 12788, 3, 16002, 13254, 292, 16006, 16001, 16000, 7421, 292, 14, 894, 524, 16002, 13254, 292, 16003, 16001, 16000, 7421, 292, 96, 19, 8, 47, 130, 3, 95, 115, 795, 13, 25, 5, 4394, 250, 13, 36, 574, 191, 3, 4, 600, 68, 5, 74, 93, 7, 946, 203, 3, 16002, 13254, 292, 16005, 16001, 16000, 7421, 292, 860, 10, 29, 43, 21, 16002, 13254, 292, 16004, 16001, 16000, 7421, 292, 4, 10, 122, 284, 14, 10, 15, 8, 47, 61, 158, 3, 70, 146, 51, 3, 16002, 13254, 292, 16005, 16001, 16000, 7421, 292, 4, 81, 24, 35, 5, 161, 30, 35, 98, 153, 4, 2160, 27, 3, 96, 6, 492, 6, 63, 8, 30, 53, 78, 3, 16002, 13254, 292, 16004, 16001, 16000, 7421, 292, 4, 68, 31, 211, 11, 18, 953, 6, 23, 22, 166, 78, 3, 4, 170, 9, 248, 21, 11, 8, 205, 30, 3, 16002, 13254, 292, 16005, 16001, 16000, 7421, 292, 181, 91, 16002, 13254, 292, 16006, 16001, 16000, 7421, 292, 6541, 23, 363, 3, 83, 11, 451, 3237, 4954, 34, 16002, 13254, 292, 16006, 16001, 16000, 7421, 292, 61, 13, 36, 47, 16002, 13254, 292, 16004, 16001, 16000, 7421, 292, 39, 50, 284, 25, 22, 63, 30, 466, 348, 2601, 23, 1861, 167, 18, 142, 1569, 30, 466, 11, 5, 518, 653, 101, 3, 109, 50, 63, 532, 78, 16002, 13254, 292, 16003, 16001, 16000, 7421, 292, 116, 16002, 13254, 292, 16006, 16001, 16000, 7421, 292, 4, 590, 5, 44, 34, 45, 19, 35, 49, 35, 4, 1024, 94, 5, 2738, 15, 34, 16002, 13254, 292, 16007, 16001, 16000, 7421, 292, 6140, 135, 547, 152, 123, 14, 3, 16002, 13254, 292, 16004, 16008]\n",
      "\n",
      "<BOS>Review: It looks OK but this is definitely not for summer time. Makes me uncomfortable every time I wear it..<SEP>Rating:<1><EOS><BOS>Review: uncomfortable<SEP>Rating:<1><EOS><BOS>Review: decent sneaker for price<SEP>Rating:<3><EOS><BOS>Review: very comfortable<SEP>Rating:<3><EOS><BOS>Review: As soon as I opened the package, I noticed a stain on the front that appeared to look like dry glue (or dry snot).<SEP>Rating:<0><EOS><BOS>Review: Fits just like any other Sperry and holds up great too.<SEP>Rating:<4><EOS><BOS>Review: Love wranglers and these are no exception. They wear well and wash well. I will always buy wranglers, they are go-to jeans...<SEP>Rating:<3><EOS><BOS>Review: A LITTLE ON THE CHEAP END BUT IT'S FOR MY WORK WATCH ..SO I HAPPY STILL HOLDING UP...<SEP>Rating:<1><EOS><BOS>Review: I really like this watch but the wrist band broke, I have ordered a replacement<SEP>Rating:<2><EOS><BOS>Review: Nostalgic. Reminds me of my early days in Alabama.<SEP>Rating:<3><EOS><BOS>Review: it broke already<SEP>Rating:<0><EOS><BOS>Review: These are a good product. My only complaint is that the jet black is not dark enough. I absolutely love the little color and barely there.<SEP>Rating:<2><EOS><BOS>Review: Don't like them<SEP>Rating:<1><EOS><BOS>Review: I'd say it's a good quality bra. It fits well.<SEP>Rating:<2><EOS><BOS>Review: I bought these as the same size as other jeans I currently have. These, however, were a size too small.<SEP>Rating:<1><EOS><BOS>Review: I love this boots for my grandson, but they run small. I need to return them for a larger size.<SEP>Rating:<2><EOS><BOS>Review: Good buy<SEP>Rating:<3><EOS><BOS>Review: Snug but comfy. Great for those chilly mornings!<SEP>Rating:<3><EOS><BOS>Review: quality is not good<SEP>Rating:<1><EOS><BOS>Review: The pants say that they were size 32x29 but NO way my husband uses size 32 for the past 40 years. This pants were extremely small<SEP>Rating:<0><EOS><BOS>Review: no<SEP>Rating:<3><EOS><BOS>Review: I LOVE the shoes! They are as comfortable as I remember from the 90s!<SEP>Rating:<4><EOS><BOS>Review: Ripped right away after wearing it.<SEP>Rating:<1>PAD\n",
      "\n",
      "<BOS>Review: They broke when I tried to put them on for the first time. They don't have any stretch; they just break.<SEP>Rating:<0><EOS><BOS>Review: its quality is not very good, and price is not cheap, you can get similar products in local markets or stores at lower price.<SEP>Rating:<1><EOS><BOS>Review: I gave this as part of my wife Christmas. She loved them and wears them often. The locks works good and securely.<SEP>Rating:<4><EOS><BOS>Review: My goodness...I couldn't get these on! Had to return.<SEP>Rating:<0><EOS><BOS>Review: Love the silky feel of the tights<SEP>Rating:<3><EOS><BOS>Review: Fit my shoes perfectly.<SEP>Rating:<4><EOS><BOS>Review: If these are a 44 then I must be the queen of England.<SEP>Rating:<0><EOS><BOS>Review: Size is way off<SEP>Rating:<1><EOS><BOS>Review: This is a nice light weight sweatshirt and a great buy for the price.<SEP>Rating:<3><EOS><BOS>Review: a little stiff at first but i fully expect carhart to be that way...fits great and looks great!<SEP>Rating:<4><EOS><BOS>Review: Not real brand. Converse label on wrong sides idiots<SEP>Rating:<0><EOS><BOS>Review: small<SEP>Rating:<1><EOS><BOS>Review: They are decent shoes. Material quality is good but the color fades very quickly. Not as black in person as shown.<SEP>Rating:<2><EOS><BOS>Review: It's been 3 months. Still no shoes.<SEP>Rating:<0><EOS><BOS>Review: Perfect.<SEP>Rating:<3><EOS><BOS>Review: A little smaller than my original bra of the same model.<SEP>Rating:<2><EOS><BOS>Review: great<SEP>Rating:<3><EOS><BOS>Review: had to return this item. Not what I had expected it to be.<SEP>Rating:<2><EOS><BOS>Review: Fits as expected.<SEP>Rating:<4><EOS><BOS>Review: These pants fit well but they tend to wrinkle quite a bit. At this price I think there are better options.<SEP>Rating:<2><EOS><BOS>Review: Would have been great if the sizes did not run too small.<SEP>Rating:<2><EOS><BOS>Review: Not happy<SEP>Rating:<0><EOS><BOS>Review: The inside of this wallet is man made materials. Not all leather as advertised.<SEP>Rating:<2><EOS><BOS>Review: nice pants.<SEP>Rating:<4>PADPADPADPADPADPADPADPADPADPADPADPADPADPAD\n",
      "\n",
      "<BOS>Review: Cute lil T-shirt bra, very comfortable. Not the most supportive bra ever not having wires, but it works well enough!<SEP>Rating:<3><EOS><BOS>Review: size was not right<SEP>Rating:<1><EOS><BOS>Review: Happy with choice.<SEP>Rating:<3><EOS><BOS>Review: these are really cool and are a must add to any marriage<SEP>Rating:<4><EOS><BOS>Review: This is my forth pair of field timberland boots. These boots came out some years back but they are a all time favorite for me!<SEP>Rating:<3><EOS><BOS>Review: Wrong size came I ordered a 9.5 and received a baby size 4....<SEP>Rating:<0><EOS><BOS>Review: A birthday gift for my five year old grand niece. She is learning how to tell time, and loves the butterflies.<SEP>Rating:<4><EOS><BOS>Review: That was my fault ordered wrong size<SEP>Rating:<1><EOS><BOS>Review: I bought my normal size but they were tighter than other pants I own. I suggest getting the next size up when ordering<SEP>Rating:<2><EOS><BOS>Review: My parents wernt even hemed at the bottom strainds of the pants were coming off straight out of the package<SEP>Rating:<0><EOS><BOS>Review: This was used as a Christmas gift and the person I bought it for loves it. It fit great and he said he would recommend it to anyone.<SEP>Rating:<3><EOS><BOS>Review: Happy with product<SEP>Rating:<4><EOS><BOS>Review: Too small<SEP>Rating:<0><EOS><BOS>Review: i ordered plus size and it was way too small<SEP>Rating:<0><EOS><BOS>Review: The picture of the hook makes it appear quite a bit larger than it actually is. The quality is fine but thought it was larger.<SEP>Rating:<2><EOS><BOS>Review: This is advertised as a size 13 shoe, but it is too short. It cramps my toes, and causes my toenails to curl.<SEP>Rating:<1><EOS><BOS>Review: These are my favorite. I will be purchasing more in the future.<SEP>Rating:<4><EOS><BOS>Review: Bad fit. Gave to GoodWill.<SEP>Rating:<0><EOS><BOS>Review: Comfty shoes! Well made and last much longer than some of the other brands I've bought in the past. Good price too!<SEP>Rating:<3><EOS><BOS>Review: My only work/ride boot!<SEP>Rating:<4>PADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPAD\n",
      "\n",
      "<BOS>Review: Little tight Loose fit is better for me<SEP>Rating:<1><EOS><BOS>Review: Dockers are Dockers good pants and budget friendly..<SEP>Rating:<2><EOS><BOS>Review: Good!<SEP>Rating:<4><EOS><BOS>Review: Great shoes in every color.<SEP>Rating:<4><EOS><BOS>Review: Waist perfect. Legs too wide.<SEP>Rating:<1><EOS><BOS>Review: Been wearing these for some years. Very comfortable casual, run errands shoe.<SEP>Rating:<3><EOS><BOS>Review: pants came on time,fit well and so far are what i wanted. didn't shrink when washed and are well made.<SEP>Rating:<3><EOS><BOS>Review: Order was ABSOLUTELY TERRIBLE. Completely wrong color - I ordered the grey and black and they are some awful brown color. Never ordering again.<SEP>Rating:<0><EOS><BOS>Review: The pack had a hole.<SEP>Rating:<0><EOS><BOS>Review: Shoes came with marks on the front white part. Had to return.<SEP>Rating:<1><EOS><BOS>Review: These sizes was nothing like the sizes in the department store much smaller plus can't even get a belt to go through the belt loops... disappointed<SEP>Rating:<0><EOS><BOS>Review: Great shoe - wish there were arch supports for my child though.<SEP>Rating:<3><EOS><BOS>Review: The waist was good, but pant leg was extremely long. I had to get them hemmed.<SEP>Rating:<3><EOS><BOS>Review: Tried on another color in store but this color didn't fit the same. Will have to exchange.<SEP>Rating:<1><EOS><BOS>Review: great<SEP>Rating:<4><EOS><BOS>Review: Way oversized!<SEP>Rating:<1><EOS><BOS>Review: Returned because pants not a true 34\"x32\". I will buy at the local store instead<SEP>Rating:<1><EOS><BOS>Review: My daughter says these shoes hurt her but they are cute. : (<SEP>Rating:<1><EOS><BOS>Review: Not the same as the last I bought of same style... pockets have lighter/cheaper lining. Still same look and fit. Good work pants.<SEP>Rating:<3><EOS><BOS>Review: its ok<SEP>Rating:<2><EOS><BOS>Review: Love the T-Shirt..... Comfortable and well made...<SEP>Rating:<4><EOS><BOS>Review: they're converse<SEP>Rating:<3><EOS><BOS>Review: This showed up white, not blush.<SEP>Rating:<1><EOS><BOS>Review: good one<SEP>Rating:<4>PADPADPADPADPADPADPADPADPAD\n",
      "\n",
      "<BOS>Review: The pants are okay. The feel is a little stiff, do to material, but all in all for the price... not bad.<SEP>Rating:<2><EOS><BOS>Review: Ran small & weren't what I expected . Uppers were man made material instead of the leather I ordered. Very disappointed.<SEP>Rating:<0><EOS><BOS>Review: Too small even when I ordered the right size!<SEP>Rating:<0><EOS><BOS>Review: Been a while since I ordered Chucks but feel a bit narrow so probably 1\\2 size larger might help. But I plan to keep them.<SEP>Rating:<3><EOS><BOS>Review: Love this watch .good looking terrific watch . Gives me everything I want at a glance<SEP>Rating:<4><EOS><BOS>Review: wish there would have been an relaxed fit.<SEP>Rating:<2><EOS><BOS>Review: Excellent....fit perfect...fast shipping...recommend<SEP>Rating:<4><EOS><BOS>Review: I ordered an infant/toddler size 4. That is what the box said, but inside was a womens 5 and mens 6.<SEP>Rating:<0><EOS><BOS>Review: 2 sizes to big and different style then the picture. Very disappointed<SEP>Rating:<0><EOS><BOS>Review: Love these shoes!<SEP>Rating:<3><EOS><BOS>Review: ok<SEP>Rating:<2><EOS><BOS>Review: Usable but confining. Do not stretch like I need.<SEP>Rating:<1><EOS><BOS>Review: The quality seemed fine but they were just too small.<SEP>Rating:<1><EOS><BOS>Review: Won't buy them again. very cheaply made. After several washings they look ready for the rag bag.<SEP>Rating:<2><EOS><BOS>Review: Needed a size 10<SEP>Rating:<1><EOS><BOS>Review: had 3 holes<SEP>Rating:<1><EOS><BOS>Review: My tiny delicate hands frayed these quite easily.<SEP>Rating:<1><EOS><BOS>Review: Do run large! But after you dry them the do shrink to the perfect size. The person I ordered them for loves them!!! Will order more!!!<SEP>Rating:<4><EOS><BOS>Review: nice shoes, like the color<SEP>Rating:<3><EOS><BOS>Review: Great pants , they were 36 -31 which aren't sold in stores .<SEP>Rating:<4><EOS><BOS>Review: Very big in size<SEP>Rating:<1><EOS><BOS>Review: would not buy again<SEP>Rating:<1><EOS><BOS>Review: Fits good<SEP>Rating:<4><EOS><BOS>Review: The shoes are beautiful, but too snug over the instep.<SEP>Rating:<2>\n",
      "\n",
      "y\n",
      "tensor([[ 7421,   292,    70,  ..., 16004, 16001, 16008],\n",
      "        [ 7421,   292,    45,  ..., 16008, 16008, 16008],\n",
      "        [ 7421,   292,  1507,  ..., 16008, 16008, 16008],\n",
      "        [ 7421,   292,   824,  ..., 16008, 16008, 16008],\n",
      "        [ 7421,   292,    39,  ...,   292, 16005, 16001]])\n",
      "torch.Size([5, 504])\n",
      "lengths\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (x, y, lengths) in enumerate(train_loader):\n",
    "    print(\"bi\")\n",
    "    print(batch_idx)\n",
    "    print(\"x\")\n",
    "    print(x.shape)\n",
    "    xl = x[0].tolist()\n",
    "    print(xl)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    print(decode_seq(x[0].tolist()))\n",
    "    print()\n",
    "    print(decode_seq(x[1].tolist()))\n",
    "    print()\n",
    "    print(decode_seq(x[2].tolist()))\n",
    "    print()\n",
    "    print(decode_seq(x[3].tolist()))\n",
    "    print()\n",
    "    print(decode_seq(x[4].tolist()))\n",
    "    print()\n",
    "    print(\"y\")\n",
    "    print(y)\n",
    "    print(y.shape)\n",
    "    print(\"lengths\")\n",
    "    print(lengths.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c553b33d-3abc-4f4e-96ba-c6e56fbf37bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "CUDA device count: 1\n",
      "Current CUDA device name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use the CPU.\")\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70e18ed8-d2cc-4928-8ac3-3bdf65780839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim, num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_dim, embed_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, causal_mask, padding_mask):\n",
    "        # Self-attention (GPT-style)\n",
    "        h = self.ln1(x)\n",
    "        attn_out, _ = self.attn(\n",
    "            h, h, h,\n",
    "            attn_mask=causal_mask,\n",
    "            key_padding_mask=padding_mask,\n",
    "            need_weights=False\n",
    "        )\n",
    "        x = x + attn_out\n",
    "\n",
    "        # Feedforward\n",
    "        h = self.ln2(x)\n",
    "        ff_out = self.mlp(h)\n",
    "        x = x + ff_out\n",
    "\n",
    "        return x\n",
    "class DecoderOnlyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len=512,\n",
    "                 embed_dim=1024, num_heads=8,\n",
    "                 num_layers=4, mlp_dim=2048, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.pos = nn.Embedding(max_len, embed_dim)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            GPTBlock(embed_dim, num_heads, mlp_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.ln_final = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, vocab_size, bias=False)\n",
    "        #self.head.weight = self.embed.weight  # weight tying\n",
    "\n",
    "    #def causal_mask(self, T, device):\n",
    "    #    mask = torch.triu(torch.ones(T, T, device=device), 1)\n",
    "    #    return mask * float(\"-inf\")\n",
    "\n",
    "    def causal_mask(self, T, device): \n",
    "        mask = torch.triu(torch.ones(T, T, device=device), 1) \n",
    "        return mask.masked_fill(mask == 1, float('-inf'))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x, lengths=None):\n",
    "        B, T = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        tok = self.embed(x)\n",
    "        pos = self.pos(torch.arange(T, device=device)[None, :])\n",
    "        h = tok + pos\n",
    "\n",
    "        causal = self.causal_mask(T, device)     # (T, T)\n",
    "        pad_mask = (x == 0)                      # (B, T)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, causal, pad_mask)\n",
    "\n",
    "        h = self.ln_final(h)\n",
    "        return self.head(h)                      # (B, T, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d28f38d8-8731-4171-8795-44da6aca6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, epochs=10, lr=1e-4, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    track_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        loader = tqdm(train_loader)\n",
    "        \n",
    "        for x, y, lengths in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(x, lengths)\n",
    "            \n",
    "            # Reshape for loss calculation\n",
    "            logits = logits.view(-1, logits.size(-1))\n",
    "            y = y.view(-1)\n",
    "            \n",
    "            loss = criterion(logits, y)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            track_loss.append(loss.item())\n",
    "            avg_loss = sum(track_loss[-10:]) / 10\n",
    "            loader.set_postfix(loss=avg_loss)\n",
    "            del logits\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "36b60908-11f5-444c-93ae-fd8c2568c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TokenDatasetB(train_seqs_x, train_seqs_y)\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fnB)\n",
    "\n",
    "\n",
    "# Initialize model (set vocab_size to your tokenizer's vocab size + special tokens)\n",
    "vocab_size = 16000+9  # Adjust based on your tokenizer\n",
    "model = DecoderOnlyTransformer(vocab_size=vocab_size,  num_layers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8a8ea1a7-ac2e-4361-acea-13086fd9662d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 670924800\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "47aff4d4-b6ea-49ed-83f2-6e2d656301d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]/home/rohan/Desktop/berkeley/cs182/cs182/lib/python3.10/site-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.55 GiB of which 40.31 MiB is free. Process 11637 has 4.98 GiB memory in use. Including non-PyTorch memory, this process has 10.08 GiB memory in use. Of the allocated memory 9.61 GiB is allocated by PyTorch, and 167.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[85], line 31\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, epochs, lr, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     30\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     34\u001b[0m track_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Desktop/berkeley/cs182/cs182/lib/python3.10/site-packages/torch/optim/optimizer.py:517\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    513\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    514\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m             )\n\u001b[0;32m--> 517\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    520\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/berkeley/cs182/cs182/lib/python3.10/site-packages/torch/optim/optimizer.py:82\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 82\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Desktop/berkeley/cs182/cs182/lib/python3.10/site-packages/torch/optim/adam.py:237\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    234\u001b[0m     state_steps: \u001b[38;5;28mlist\u001b[39m[Tensor] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    235\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 237\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     adam(\n\u001b[1;32m    248\u001b[0m         params_with_grad,\n\u001b[1;32m    249\u001b[0m         grads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m         decoupled_weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoupled_weight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    269\u001b[0m     )\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Desktop/berkeley/cs182/cs182/lib/python3.10/site-packages/torch/optim/adam.py:177\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[0;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    167\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    168\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    169\u001b[0m         (),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m_get_scalar_dtype())\n\u001b[1;32m    175\u001b[0m )\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# Exponential moving average of gradient values\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_avg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[1;32m    181\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_avg_sq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(\n\u001b[1;32m    182\u001b[0m     p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format\n\u001b[1;32m    183\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.55 GiB of which 40.31 MiB is free. Process 11637 has 4.98 GiB memory in use. Including non-PyTorch memory, this process has 10.08 GiB memory in use. Of the allocated memory 9.61 GiB is allocated by PyTorch, and 167.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = train_model(model, train_loader, epochs=20, lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e21d8c29-ba36-41fe-9509-a107481bfbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [345, 23, 44, 99]\n",
    "kt = torch.tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65c02368-8230-4a74-b928-61157375ed3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcc225f7-a78e-4020-9977-d1fb388eb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno, score = getEncodingOpen(test_df, random.randint(0,len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbb9608b-ed31-42d0-a4cd-b94fdbe089c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51741/4078374235.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  annot = torch.tensor(anno)\n"
     ]
    }
   ],
   "source": [
    "annot = torch.tensor(anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ca34894-ec80-4b12-ba7e-3bbaad8b7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS>Review: These briefs run a bit small. I would order one size larger for a better fit. I also felt that they were to thin.<SEP>Rating:'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq(anno.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f690c9bb-2855-4205-a7a4-0ace3d698c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16000,  7421,   292,    96,  1617,   166,     8,   120,    78,     3,\n",
       "            4,    69,   138,    62,    30,   205,    11,     8,   176,    26,\n",
       "            3,     4,   172,   516,    25,    22,    63,     9,   387,     3,\n",
       "        16002, 13254,   292])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "366e1343-ffe1-437c-986d-0c836039f334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afdf5a43-2b53-4a28-b6d9-623da3bcd233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51741/1037303179.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padded_x[0,:lens] = torch.tensor(anno)\n"
     ]
    }
   ],
   "source": [
    "lens = len(anno)\n",
    "anno_len = torch.tensor([lens])\n",
    "\n",
    "# Pad sequences\n",
    "padded_x = torch.zeros(1, 512, dtype=torch.long) + pad_token\n",
    "padded_x[0,:lens] = torch.tensor(anno)\n",
    "\n",
    "padded_x = padded_x.to(device)\n",
    "anno_len = anno_len.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31be58a7-a52f-4ae5-ace2-6794c1b57754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c49ebd3-5b50-43d0-86d2-69d2c1f68576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS>Review: These briefs run a bit small. I would order one size larger for a better fit. I also felt that they were to thin.<SEP>Rating:PADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPAD'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq(padded_x[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c3453a3-b20d-46b8-874f-6afb88d26fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(padded_x, anno_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37a76155-a067-4e39-817e-3312373d71ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 16009])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f36c7b5-4122-4c48-8bef-970b56dc5898",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenout = torch.argmax(out,dim=2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77190548-0dfa-4912-9462-ccd4e0f5e6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f9a6132-6236-43fc-8b02-22ea37a78894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0dada6bd-507c-4bf3-90d5-53036f14bd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Review: I are way way 34 too<SEP>I have buy product to if than me woman fit good<SEP>love very like are just perfect send that<SEP>Rating:<1>PADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPAD'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_seq(tokenout.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54d0ba14-4687-46de-a45c-49d702ce45e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_probs: [[0.2941319  0.405071   0.17341492 0.11416022 0.01129261]]\n",
      "top5 ids: [[16004 16003 16005 16006 16007]]\n"
     ]
    }
   ],
   "source": [
    "def predict_label_ids(model, x, pad_token):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)                    # (B, T, V)\n",
    "        nonpad_len = (x != pad_token).sum(dim=1)   # (B,)\n",
    "        last_pos = nonpad_len - 1\n",
    "        last_logits = logits[torch.arange(x.size(0)), last_pos]   # (B, V)\n",
    "        probs = last_logits.softmax(dim=-1)\n",
    "        top5 = probs.topk(5, dim=-1)\n",
    "        return top5, probs[:, 16003:16008]   # top5 and probs specifically for label tokens\n",
    "\n",
    "# Example:\n",
    "#x = torch.LongTensor([padded_x]).to(device)\n",
    "top5, label_probs = predict_label_ids(model, padded_x, pad_token)\n",
    "print(\"label_probs:\", label_probs.cpu().numpy())\n",
    "print(\"top5 ids:\", top5.indices.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "056021ea-c2ee-4b3b-83a1-a39e04cb3a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICLDataset(Dataset):\n",
    "    def __init__(self, df, shots, seq_len):\n",
    "        self.df = df\n",
    "        self.shots = shots\n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def getpre(self, idx, l):\n",
    "        for _ in range(10):\n",
    "            ixs = []\n",
    "            xs = []\n",
    "            for j in range(self.shots):\n",
    "                sel = idx\n",
    "                while(sel==idx):\n",
    "                    sel = random.randint(0, self.__len__() -1)\n",
    "                xs.extend(getEncoding(self.df, sel))\n",
    "            if(len(xs) + l <= seq_len):\n",
    "                return torch.LongTensor(xs)\n",
    "        raise ValueError(f\"can't fit {self.shots} examples in context\")\n",
    "                \n",
    "            \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = getEncodingOpen(self.df, idx)\n",
    "        l = len(x)\n",
    "        pre = self.getpre(idx, l)\n",
    "        icl_x = torch.cat((pre,x))\n",
    "        return icl_x, y\n",
    "\n",
    "# Padding collate function for variable length sequences\n",
    "def collate_fn_icl(batch):\n",
    "    seqs_x, y = zip(*batch)\n",
    "    lens = [len(s) for s in seqs_x]\n",
    "    max_len = max(lens)\n",
    "    \n",
    "    # Pad sequences\n",
    "    padded_x = torch.zeros(len(seqs_x), max_len, dtype=torch.long) + pad_token\n",
    "    \n",
    "    for i, x in enumerate(seqs_x):\n",
    "        padded_x[i, :len(x)] = x\n",
    "    \n",
    "    return padded_x, torch.LongTensor(y), torch.LongTensor(lens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a205d72-f62a-4c03-8f30-01030aebbc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_dataset = ICLDataset(train_df, 0, seq_len)\n",
    "icl_loader = DataLoader(icl_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn_icl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2cefcec9-c47a-4681-9065-2b98bd131630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi\n",
      "0\n",
      "x\n",
      "torch.Size([8, 34])\n",
      "[16000, 7421, 292, 95, 182, 133, 14, 3, 16002, 13254, 292, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008]\n",
      "\n",
      "<BOS>Review: My son loves it.<SEP>Rating:PADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPADPAD\n",
      "y\n",
      "tensor([4, 2, 1, 3, 3, 3, 0, 2])\n",
      "torch.Size([8])\n",
      "lengths\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (x, y, lengths) in enumerate(icl_loader):\n",
    "    print(\"bi\")\n",
    "    print(batch_idx)\n",
    "    print(\"x\")\n",
    "    print(x.shape)\n",
    "    xl = x[0].tolist()\n",
    "    print(xl)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    print(decode_seq(xl))\n",
    "    print(\"y\")\n",
    "    print(y)\n",
    "    print(y.shape)\n",
    "    print(\"lengths\")\n",
    "    print(lengths.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "884c4939-b40f-4f44-a047-71c0b6e6da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def israting(s):\n",
    "    bnk = [\"0\",\"1\",\"2\",\"3\",\"4\"]\n",
    "    return s in bnk\n",
    "def isnum(s):\n",
    "    bnk = [str(n) for n in range(0,20)]\n",
    "    return s in bnk\n",
    "\n",
    "def check_token_list(token_list):\n",
    "    isratings = 0\n",
    "    isnums = 0\n",
    "    for token in token_list:\n",
    "        isratings += 1 if israting(token) else 0\n",
    "        isnums += 1 if isnum(token) else 0\n",
    "    return isratings, isnums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12cdc769-40a8-447f-86e1-272ae6ce03bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{16000: '<BOS>',\n",
       " 16001: '<EOS>',\n",
       " 16002: '<SEP>',\n",
       " 16003: '<0>',\n",
       " 16004: '<1>',\n",
       " 16005: '<2>',\n",
       " 16006: '<3>',\n",
       " 16007: '<4>',\n",
       " 16008: 'PAD'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7380fe5d-f0f6-4cea-9491-67dc979a59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(x):\n",
    "    x = x.tolist()\n",
    "    for i in range(len(x)-1,0, -1):\n",
    "        if 16003<= x[i] <=16007:\n",
    "            return x[i]\n",
    "    return 20000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "014392b4-ea3b-4882-879f-5ede3409a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ex = torch.tensor([ 7421,   292,     4,     6,   945,    35,   161,    19,    31,   161,\n",
    "             6,    18,   161,    19,    10,    29,    26,   143,   204,     3,\n",
    "            28,   321,    14,   143,    75,   460, 13254,   292, 16000, 16008,\n",
    "         16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008,\n",
    "         16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008,\n",
    "         16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008, 16008,\n",
    "         16008])\n",
    "vv = get_score(test_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06cd2534-def8-4717-961a-303c3ad4801a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c91d546-ca7f-4e19-ae3b-43561b358d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenScore(t):\n",
    "    if(t==20000):\n",
    "        return '-'\n",
    "    return d[t][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8caae84-5041-4f0f-a364-73ec24e13b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_dataset = ICLDataset(train_df, 0, seq_len)\n",
    "icl_loader = DataLoader(icl_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn_icl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "755ae39c-767c-4cd6-b79a-d9f814cd9061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 22])\n",
      "tensor([16000,  7421,   292,  1087,     9,    46,   869,    35,     9,    26,\n",
      "            3, 16002, 13254,   292, 16008, 16008, 16008, 16008, 16008, 16008,\n",
      "        16008, 16008], device='cuda:0')\n",
      "<BOS>Review: Seem to be okay as to fit.<SEP>Rating:PADPADPADPADPADPADPADPAD\n",
      "\n",
      "<BOS>Review: Material is very bad quality. It does not look anything like the pictures online.<SEP>Rating:\n",
      "\n",
      "<BOS>Review: I wear a 36 had to get a 38<SEP>Rating:PADPADPADPADPADPADPAD\n",
      "\n",
      "<BOS>Review: Had to return them because they didn't fit my wifes foot. :(<SEP>Rating:\n",
      "\n",
      "<BOS>Review: The product was not as described.<SEP>Rating:PADPADPADPADPADPADPADPADPAD\n",
      "\n",
      "<BOS>Review: 2-3 sizes to small<SEP>Rating:PADPADPADPADPADPADPADPADPADPADPADPAD\n",
      "\n",
      "<BOS>Review: good hose. lasts more than once like some of the cheaper ones out there.<SEP>Rating:\n",
      "\n",
      "<BOS>Review: These were too baggy for my taste. They do look good though.<SEP>Rating:PADPAD\n",
      "\n",
      "========================\n",
      "Review: Is run well. I put.<SEP>Rating:<0>PADPADPADPADPADPADPADPAD\n",
      "\n",
      "Review: I watch too nice quality and You' not fit like, the right. with You Rating:<0>\n",
      "\n",
      "Review: I have this 32 waist to return them wedding waist Rating:<1>PADPADPADPADPADPADPAD\n",
      "\n",
      "Review: I one return. before I were't know right feet is..<SEP><SEP>Rating:<0>\n",
      "\n",
      "Review: I description was larger as durable. Also Rating:<1>PADPADPADPADPADPADPADPADPAD\n",
      "\n",
      "Review: I sizes too small. Rating:<0>PADPADPADPADPADPADPADPADPADPADPADPAD\n",
      "\n",
      "Review: I<SEP>when Not the than normal! a only the stocking of I of<SEP><SEP>Rating:<3>\n",
      "\n",
      "Review: I were for small. everyday daughter. I are with and with.<SEP>Rating:<0>PADPAD\n",
      "\n",
      "[16003, 16003, 16004, 16003, 16004, 16003, 16006, 16003]\n",
      "---\n",
      "['0', '0', '1', '0', '1', '0', '3', '0']\n",
      "['3', '1', '3', '1', '0', '0', '4', '2']\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "num = 0\n",
    "ratings = 0\n",
    "correct = 0\n",
    "for batch_idx, (x, y, lengths) in enumerate(icl_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    pred_logits = model(x,lengths)\n",
    "    print(x.shape)\n",
    "    print(x[0])\n",
    "    for sequence in x:\n",
    "        print(decode_seq(sequence.tolist()))\n",
    "        print()\n",
    "    print(\"========================\")\n",
    "    pred_tokens = torch.argmax(pred_logits,dim=2)\n",
    "    pred_tokens = pred_tokens.to('cpu')\n",
    "    #pred_tokens = trim_tail(pred_tokens, pad_token)\n",
    "    #pred_last_token = pred_tokens[:,-1].tolist()\n",
    "    pred_last_token = [get_score(i) for i in pred_tokens]\n",
    "    for sequence in pred_tokens:\n",
    "        print(decode_seq(sequence.tolist()))\n",
    "        print()\n",
    "    pred_scores = []\n",
    "    print(pred_last_token)\n",
    "    for token in pred_last_token:\n",
    "        if(token<=15999):\n",
    "            pred_scores.append(tok.decode([token]))\n",
    "        else:\n",
    "            pred_scores.append(getTokenScore(token))\n",
    "\n",
    "    print('---')\n",
    "    print(pred_scores)\n",
    "    \n",
    "    ys = [str(ans) for ans in y.tolist()]\n",
    "    print(ys)\n",
    "    tot += len(y)\n",
    "    for t in range(len(y)):\n",
    "        correct += 1 if pred_scores[t] == ys[t] else 0\n",
    "    isratings, isnums = check_token_list(pred_scores)\n",
    "    num += isnums\n",
    "    ratings += isratings\n",
    "    torch.cuda.empty_cache()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f502f9f4-9814-46d8-9f57-75d87a636bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot:  8\n",
      "num:  8\n",
      "ratings:  8\n",
      "correct:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"tot: \", tot)\n",
    "print(\"num: \", num)\n",
    "print(\"ratings: \", ratings)\n",
    "print(\"correct: \", correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4321cea4-bb42-4134-88bf-b6f6411167ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_dataset = ICLDataset(test_df, 0, seq_len)\n",
    "icl_loader = DataLoader(icl_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn_icl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68778e4c-f65d-426b-8099-ac08645be7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "num = 0\n",
    "ratings = 0\n",
    "correct = 0\n",
    "for batch_idx, (x, y, lengths) in enumerate(icl_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    pred_logits = model(x,lengths)\n",
    "    #print(x.shape)\n",
    "    #print(x[0])\n",
    "    #for sequence in x:\n",
    "    #    print(decode_seq(sequence.tolist()))\n",
    "    #    print()\n",
    "    #print(\"========================\")\n",
    "    pred_tokens = torch.argmax(pred_logits,dim=2)\n",
    "    pred_tokens = pred_tokens.to('cpu')\n",
    "    #pred_tokens = trim_tail(pred_tokens, pad_token)\n",
    "    #pred_last_token = pred_tokens[:,-1].tolist()\n",
    "    pred_last_token = [get_score(i) for i in pred_tokens]\n",
    "    #for sequence in pred_tokens:\n",
    "    #    print(decode_seq(sequence.tolist()))\n",
    "    #    print()\n",
    "    pred_scores = []\n",
    "    #print(pred_last_token)\n",
    "    for token in pred_last_token:\n",
    "        if(token<=15999):\n",
    "            pred_scores.append(tok.decode([token]))\n",
    "        else:\n",
    "            pred_scores.append(getTokenScore(token))\n",
    "\n",
    "    #print('---')\n",
    "    #print(pred_scores)\n",
    "    \n",
    "    ys = [str(ans) for ans in y.tolist()]\n",
    "    #print(ys)\n",
    "    tot += len(y)\n",
    "    for t in range(len(y)):\n",
    "        correct += 1 if pred_scores[t] == ys[t] else 0\n",
    "    isratings, isnums = check_token_list(pred_scores)\n",
    "    num += isnums\n",
    "    ratings += isratings\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2392f1a0-5382-4455-9c0a-6671064f7615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot:  2300\n",
      "num:  2300\n",
      "ratings:  2300\n",
      "correct:  844\n",
      "acc:  0.36695652173913046\n"
     ]
    }
   ],
   "source": [
    "print(\"tot: \", tot)\n",
    "print(\"num: \", num)\n",
    "print(\"ratings: \", ratings)\n",
    "print(\"correct: \", correct)\n",
    "print(\"acc: \", correct/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78220f0-c788-4320-9ee4-3f419734acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "5358/15387 #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214ac781-88b8-4897-926b-2ed66d48c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    " 4778 / 15396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2fd914-8d64-45f4-afb8-2cece4e8d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473732a9-db08-4199-9b61-11a7d9685629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
